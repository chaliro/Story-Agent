import os
import json
import re
import dotenv
from typing import TypedDict, List, Dict, Optional, Any, Literal
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import PromptTemplate
import pprint
from utils import get_llm, get_evaluation_llm, get_llm_user

# ================================================================= #
# 1. ç¯å¢ƒä¸æ¨¡å‹è®¾ç½®
# ================================================================= #

# ================================================================= #
# 2. æ‰©å±•çš„çŸ¥è¯†åº“ç»“æ„å®šä¹‰ (å·²æ›´æ–°) & Pydantic æ¨¡å‹
# ================================================================= #

RelationshipStatus = Literal[
    "æœ‹å‹", "æ‹äºº", "æ•Œäºº", "é™Œç”Ÿäºº", "å®¶åº­æˆå‘˜", "åˆä½œä¼™ä¼´", "ç«äº‰å¯¹æ‰‹", "åˆæ¬¡è§é¢", "åˆç§Ÿå®¤å‹"]


class CharacterProfile(TypedDict):
    """æ‰©å±•çš„è§’è‰²æ¡£æ¡ˆ (å·²æ›´æ–°å…³ç³»å­˜å‚¨ç»“æ„)"""
    name: str
    age: Optional[int]
    gender: Optional[str]
    backstory: str
    traits: List[str]  # æ€§æ ¼ç‰¹ç‚¹
    specialties: List[str]
    hobbies: List[str]
    occupations: List[str]
    appearance: str  # å¤–è²Œæè¿°
    # --- ç»“æ„æ›´æ–° ---
    # ä½¿ç”¨å­—å…¸å­˜å‚¨ï¼Œé”®ä¸ºå¯¹æ–¹è§’è‰²åï¼Œå€¼ä¸ºå…³ç³»è¯¦æƒ…
    relationship: Dict[str, Dict[str, str]]
    first_appearance_chapter: int  # é¦–æ¬¡å‡ºç°çš„ç« èŠ‚

class KnowledgeBase(TypedDict):
    """çŸ¥è¯†åº“çš„é¡¶å±‚ç»“æ„"""
    characters: Dict[str, CharacterProfile]
    last_updated_chapter: int

# Pydantic æ¨¡å‹ç”¨äºè¾“å‡ºè§£æ
class CharacterInfo(BaseModel):
    """è§’è‰²ä¿¡æ¯æ¨¡å‹"""
    name: str = Field(description="è§’è‰²å§“å")
    estimated_age: str = Field(description="æ•°å­—/æœªçŸ¥")
    gender: str = Field(description="ç”·/å¥³/æœªçŸ¥")
    appearance: str = Field(description="å¤–è²Œæè¿°/æœªçŸ¥")
    traits: List[str] = Field(description="æ€§æ ¼ç‰¹ç‚¹åˆ—è¡¨")
    specialties: List[str] = Field(description="ç‰¹é•¿åˆ—è¡¨")
    hobbies: List[str] = Field(description="çˆ±å¥½åˆ—è¡¨")
    occupations: List[str] = Field(description="èŒä¸šåˆ—è¡¨")

class CharacterInteraction(BaseModel):
    """è§’è‰²äº’åŠ¨æ¨¡å‹"""
    character_a: str = Field(description="è§’è‰²Aå§“å")
    character_b: str = Field(description="è§’è‰²Bå§“å")
    interaction_type: str = Field(description="å…³ç³»ç±»å‹")
    interaction_summary: str = Field(description="äº’åŠ¨æè¿°")

class CharacterAnalysisResult(BaseModel):
    """è§’è‰²åˆ†æç»“æœæ¨¡å‹"""
    characters: List[CharacterInfo] = Field(description="è§’è‰²åˆ—è¡¨")
    character_interactions: List[CharacterInteraction] = Field(description="è§’è‰²äº’åŠ¨åˆ—è¡¨")

class EvidenceText(BaseModel):
    """è¯æ®æ–‡æœ¬æ¨¡å‹"""
    evidence: str = Field(description="ä»ç« èŠ‚å†…å®¹ä¸­æå–çš„äº’åŠ¨æ–‡æœ¬ç‰‡æ®µ")

class BackstorySummary(BaseModel):
    """èƒŒæ™¯æ•…äº‹æ‘˜è¦æ¨¡å‹"""
    summary: str = Field(description="è§’è‰²ä¸ªäººèƒŒæ™¯æ•…äº‹çš„æ€»ç»“")


# ================================================================= #
# 3. æ”¹è¿›çš„å·¥å…·é›† (æ ¸å¿ƒæ›´æ–°) - æ·»åŠ è¾“å‡ºè§£æåŠŸèƒ½
# ================================================================= #

def initialize_knowledge_base(KNOWLEDGE_BASE_PATH: str):
    """åˆå§‹åŒ–çŸ¥è¯†åº“æ–‡ä»¶"""
    if not os.path.exists(KNOWLEDGE_BASE_PATH):
        initial_kb = {
            "characters": {},
            "last_updated_chapter": 0
        }
        with open(KNOWLEDGE_BASE_PATH, "w", encoding="utf-8") as f:
            json.dump(initial_kb, f, ensure_ascii=False, indent=2)
        print("âœ… å·²åˆå§‹åŒ–çŸ¥è¯†åº“æ–‡ä»¶")


def get_knowledge_base(KNOWLEDGE_BASE_PATH: str) -> KnowledgeBase:
    """è·å–å½“å‰çŸ¥è¯†åº“ï¼Œå¹¶ç¡®ä¿å…¶ç»“æ„å®Œæ•´æ€§"""
    try:
        with open(KNOWLEDGE_BASE_PATH, "r", encoding="utf-8") as f:
            kb = json.load(f)

        # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„å­—æ®µéƒ½å­˜åœ¨
        if "characters" not in kb:
            kb["characters"] = {}
            print("âš ï¸  çŸ¥è¯†åº“æ–‡ä»¶ç¼ºå°‘ 'characters' å­—æ®µï¼Œå·²è‡ªåŠ¨ä¿®å¤ã€‚")

        if "last_updated_chapter" not in kb:
            kb["last_updated_chapter"] = 0
            print("âš ï¸  çŸ¥è¯†åº“æ–‡ä»¶ç¼ºå°‘ 'last_updated_chapter' å­—æ®µï¼Œå·²è‡ªåŠ¨ä¿®å¤ã€‚")

        # ã€é‡è¦ã€‘ä¸ºæ—§ç‰ˆçŸ¥è¯†åº“æ–‡ä»¶æ·»åŠ æ–°çš„ 'relationship' å­—æ®µ
        for char_name in kb["characters"]:
            if "relationship" not in kb["characters"][char_name]:
                kb["characters"][char_name]["relationship"] = {}
                print(f"âš ï¸  ä¸ºè§’è‰² '{char_name}' è‡ªåŠ¨æ·»åŠ  'relationship' å­—æ®µã€‚")

        # å¦‚æœè¿›è¡Œäº†ä¿®å¤ï¼Œä¿å­˜æ›´æ”¹
        if any("relationship" not in char for char in kb["characters"].values()):
            dotenv.load_dotenv()
            dir1 = os.getenv("MEMORY_ROOT")
            dir2 = os.getenv("CURRENT_PROJECT_ID")

            dir5 = "knowledge_base.json"

            knowledge_path = os.path.join(dir1, dir2, dir5)
            save_knowledge_base(kb, knowledge_path)

        return kb

    except FileNotFoundError:
        initialize_knowledge_base(KNOWLEDGE_BASE_PATH)
        return get_knowledge_base(KNOWLEDGE_BASE_PATH)


def save_knowledge_base(kb: KnowledgeBase, KNOWLEDGE_BASE_PATH: str):
    """ä¿å­˜çŸ¥è¯†åº“"""
    with open(KNOWLEDGE_BASE_PATH, "w", encoding="utf-8") as f:
        json.dump(kb, f, ensure_ascii=False, indent=2)


def clean_llm_response(content: str) -> str:
    """æ¸…æ´—LLMè¿”å›çš„å†…å®¹ï¼Œæå–çº¯å‡€JSON"""
    if content.startswith("```json") and content.endswith("```"):
        content = content[len("```json"):-len("```")].strip()
    json_match = re.search(r"\{[\s\S]*\}", content)
    if json_match:
        content = json_match.group().strip()
    content = content.replace("'", '\"')
    content = re.sub(r"//.*", "", content)
    content = re.sub(r"/\*[\s\S]*?\*/", "", content)
    return content


def identify_characters_in_text(text: str, current_chapter: int) -> Dict[str, Any]:
    """ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«æ–‡æœ¬ä¸­å‡ºç°çš„ä¸»è¦è§’è‰² - ä½¿ç”¨è¾“å‡ºè§£æå™¨ç‰ˆæœ¬"""
    # åˆ›å»ºè¾“å‡ºè§£æå™¨
    parser = PydanticOutputParser(pydantic_object=CharacterAnalysisResult)

    prompt_template = """
ä»»åŠ¡ï¼šåˆ†æä»¥ä¸‹å°è¯´ç« èŠ‚ï¼Œè¯†åˆ«æ‰€æœ‰ä¸»è¦è§’è‰²åŠä»–ä»¬çš„äº’åŠ¨å…³ç³»ã€‚

### ç« èŠ‚å†…å®¹
ç¬¬{current_chapter}ç« ï¼š
{text}

### è¾“å‡ºè¦æ±‚
1. å¦‚æœæœªæåŠestimated_ageã€genderã€appearanceï¼Œå¯ç”¨æœªçŸ¥ä»£æ›¿ï¼Œä¸è¦è‡ªå·±çŒœä¸€ä¸ªç»“æœ
2. traitsï¼Œhobbiesï¼Œoccupationsï¼Œspecialtiesè‹¥æ²¡æœ‰æäº¤ä¹Ÿå¯ä»¥æ˜¯æœªçŸ¥ï¼Œè‹¥åŸæ–‡æœ‰è®¾è®¡æˆ–è€…æš—ç¤ºï¼Œå¯ä»¥æ·»åŠ ç›¸åº”å†…å®¹ï¼Œè¿™å‡ ä¸ªå±æ€§éƒ½å¯ä»¥æ˜¯æœªçŸ¥ï¼Œæˆ–è€…åªæœ‰1ä¸ªå€¼æˆ–è€…å¤šä¸ªå€¼éƒ½å¯ä»¥

{format_instructions}
"""

    master_llm = get_evaluation_llm()

    try:
        prompt = PromptTemplate(
            template=prompt_template,
            input_variables=["text", "current_chapter"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )

        chain = prompt | master_llm
        raw_response = chain.invoke({
            "text": text,
            "current_chapter": current_chapter
        })

        # è¿‡æ»¤æ€è€ƒæ ‡ç­¾å¹¶è§£æ
        from helper import filter_think_tags, parse_json_with_filtering
        filtered_content = filter_think_tags(raw_response.content)
        parsed_result = parse_json_with_filtering(filtered_content, parser)

        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ä»¥ä¿æŒå‘åå…¼å®¹
        result = {
            "characters": [char.model_dump() for char in parsed_result.characters],
            "character_interactions": [interaction.model_dump() for interaction in parsed_result.character_interactions]
        }

        print(f"âœ… è§’è‰²è¯†åˆ«æˆåŠŸï¼š{len(result['characters'])}ä¸ªè§’è‰²ï¼Œ{len(result['character_interactions'])}æ¬¡äº’åŠ¨")
        return result

    except Exception as e:
        print(f"--- âŒ è§’è‰²è¯†åˆ«è¾“å‡ºè§£æå¤±è´¥: {e} ---")
        print("--- ğŸ”„ ä½¿ç”¨ä¼ ç»Ÿè§£ææ–¹æ³•ä½œä¸ºå›é€€ ---")
        return identify_characters_in_text_fallback(text, current_chapter)


def identify_characters_in_text_fallback(text: str, current_chapter: int) -> Dict[str, Any]:
    """å›é€€æ–¹æ³•ï¼šä½¿ç”¨ä¼ ç»Ÿçš„JSONè§£ææ–¹å¼"""
    prompt = f"""
ä»»åŠ¡ï¼šåˆ†æä»¥ä¸‹å°è¯´ç« èŠ‚ï¼Œè¯†åˆ«æ‰€æœ‰ä¸»è¦è§’è‰²åŠä»–ä»¬çš„äº’åŠ¨å…³ç³»ã€‚

### ç« èŠ‚å†…å®¹
ç¬¬{current_chapter}ç« ï¼š
{text}

### è¾“å‡ºè¦æ±‚ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰
1. ä»…è¿”å›æ ‡å‡†JSONï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€ä»£ç å—æ ‡è®°ã€‚
2. JSONè¯­æ³•å¿…é¡»æ­£ç¡®ï¼šé”®åç”¨åŒå¼•å·ã€å­—ç¬¦ä¸²ç”¨åŒå¼•å·ã€æ— å°¾é€—å·ã€‚
3.å¦‚æœæœªæåŠestimated_ageã€genderã€appearanceï¼Œå¯ç”¨æœªçŸ¥ä»£æ›¿ï¼Œä¸è¦è‡ªå·±çŒœä¸€ä¸ªç»“æœ
4.traitsï¼Œhobbiesï¼Œoccupationsï¼Œspecialtiesè‹¥æ²¡æœ‰æäº¤ä¹Ÿå¯ä»¥æ˜¯æœªçŸ¥ï¼Œè‹¥åŸæ–‡æœ‰è®¾è®¡æˆ–è€…æš—ç¤ºï¼Œå¯ä»¥æ·»åŠ ç›¸åº”å†…å®¹ï¼Œè¿™å‡ ä¸ªå±æ€§éƒ½å¯ä»¥æ˜¯æœªçŸ¥ï¼Œæˆ–è€…åªæœ‰1ä¸ªå€¼æˆ–è€…å¤šä¸ªå€¼éƒ½å¯ä»¥
5. JSONå›ºå®šç»“æ„å¦‚ä¸‹ï¼š
{{
    "characters": [
        {{
            "name": "è§’è‰²å§“å",
            "estimated_age": "æ•°å­—/æœªçŸ¥",
            "gender": "ç”·/å¥³/æœªçŸ¥",
            "appearance": "å¤–è²Œæè¿°/æœªçŸ¥",
            "traits": ["æ€§æ ¼ç‰¹ç‚¹1", "æ€§æ ¼ç‰¹ç‚¹2"],
            "specialties":["ç‰¹é•¿1", "ç‰¹é•¿2"]
            "hobbies":["çˆ±å¥½1", "çˆ±å¥½2"]
            "occupations":["èŒä¸š1", "èŒä¸š2"]
        }}
    ],
    "character_interactions": [
        {{
            "character_a": "è§’è‰²Aå§“å",
            "character_b": "è§’è‰²Bå§“å",
            "interaction_type": "å…³ç³»ç±»å‹ï¼ˆä»['æœ‹å‹','æ‹äºº','æ•Œäºº','é™Œç”Ÿäºº','åˆæ¬¡è§é¢', 'åˆç§Ÿå®¤å‹']ä¸­é€‰ï¼‰",
            "interaction_summary": "äº’åŠ¨æè¿°"
        }}
    ]
}}
"""
    master_llm = get_evaluation_llm()
    response = master_llm.invoke(prompt)
    cleaned_content = clean_llm_response(response.content)
    try:
        result = json.loads(cleaned_content)
        if "characters" not in result:
            result["characters"] = []
        if "character_interactions" not in result:
            result["character_interactions"] = []
        print(
            f"âœ… è§’è‰²è¯†åˆ«æˆåŠŸï¼ˆå›é€€æ–¹æ³•ï¼‰ï¼š{len(result['characters'])}ä¸ªè§’è‰²ï¼Œ{len(result['character_interactions'])}æ¬¡äº’åŠ¨")
        return result
    except json.JSONDecodeError as e:
        print("\nâŒ è§’è‰²è¯†åˆ«JSONè§£æå¤±è´¥ï¼")
        print(f"ğŸ“„ LLMåŸå§‹å“åº”ï¼š\n{response.content[:500]}...")
        print(f"ğŸ§¹ æ¸…æ´—åå†…å®¹ï¼š\n{cleaned_content[:500]}...")
        print(f"ğŸ’¥ é”™è¯¯è¯¦æƒ…ï¼š{str(e)}")
        return {"characters": [], "character_interactions": []}


def create_character_if_not_exists(name: str, age: Optional[int] = None,
                                   gender: Optional[str] = None,
                                   appearance: str = "", traits: List[str] = None,
                                   specialties: List[str] = None, hobbies: List[str] = None,
                                   occupations: List[str] = None, current_chapter: int = 0,
                                   relationship: Dict[str, Dict[str, str]] = None) -> str:
    """ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥å¹¶åˆ›å»ºè§’è‰²èŠ‚ç‚¹ (å·²æ›´æ–°)"""
    dotenv.load_dotenv()
    dir1 = os.getenv("MEMORY_ROOT")
    dir2 = os.getenv("CURRENT_PROJECT_ID")

    dir5 = "knowledge_base.json"

    knowledge_path = os.path.join(dir1, dir2, dir5)
    kb = get_knowledge_base(knowledge_path)
    traits = traits or []
    relationship = relationship or {}  # ç¡®ä¿ä¸ºå­—å…¸

    if name not in kb["characters"]:
        kb["characters"][name] = {
            "name": name,
            "age": age,
            "gender": gender,
            "backstory": "",
            "traits": traits,
            "appearance": appearance,
            "relationship": relationship,  # ä½¿ç”¨æ–°é”®
            "first_appearance_chapter": current_chapter,
            "specialties": specialties,
            "hobbies": hobbies,
            "occupations": occupations
        }

        save_knowledge_base(kb, knowledge_path)
        return f"âœ… æˆåŠŸåˆ›å»ºæ–°è§’è‰² '{name}'"
    else:
        updated_fields = []
        character = kb["characters"][name]
        if age is not None and character["age"] is None:
            character["age"] = age
            updated_fields.append(f"å¹´é¾„={age}")
        if gender is not None and character["gender"] is None:
            character["gender"] = gender
            updated_fields.append(f"æ€§åˆ«={gender}")
        if appearance and not character["appearance"]:
            character["appearance"] = appearance
            updated_fields.append("å¤–è²Œæè¿°")
        for trait in traits:
            if trait not in character["traits"] and trait.strip():
                character["traits"].append(trait.strip())
                updated_fields.append(f"æ€§æ ¼={trait}")
        for specialty in specialties:
            if specialty not in character["specialties"] and specialty.strip():
                character["specialties"].append(specialty.strip())
                updated_fields.append(f"ç‰¹é•¿={specialty}")
        for hobby in hobbies:
            if hobby not in character["hobbies"] and hobby.strip():
                character["hobbies"].append(hobby.strip())
                updated_fields.append(f"çˆ±å¥½={hobby}")
        for occupation in occupations:
            if occupation not in character["occupations"] and occupation.strip():
                character["occupations"].append(occupation.strip())
                updated_fields.append(f"èŒä¸š={occupation}")

        if updated_fields:
            save_knowledge_base(kb, knowledge_path)
            return f"âœ… æ›´æ–°è§’è‰²ï¼š{name}ï¼ˆæ›´æ–°å­—æ®µï¼š{', '.join(updated_fields)}ï¼‰"
        else:
            return f"â„¹ï¸  è§’è‰² '{name}' å·²å­˜åœ¨ï¼Œæ— éœ€æ›´æ–°"


def update_character_backstory(name: str, new_information: str,
                               mode: Literal['append', 'overwrite'] = 'append') -> str:
    """æ›´æ–°è§’è‰²èƒŒæ™¯æ•…äº‹"""
    dotenv.load_dotenv()
    dir1 = os.getenv("MEMORY_ROOT")
    dir2 = os.getenv("CURRENT_PROJECT_ID")

    dir5 = "knowledge_base.json"

    knowledge_path = os.path.join(dir1, dir2, dir5)
    kb = get_knowledge_base(knowledge_path)

    if name not in kb["characters"]:
        return f"âŒ é”™è¯¯ï¼šè§’è‰² '{name}' ä¸å­˜åœ¨ï¼Œæ— æ³•æ›´æ–°èƒŒæ™¯æ•…äº‹"

    if mode == 'append':
        if kb["characters"][name]["backstory"]:
            kb["characters"][name]["backstory"] += f"\n{new_information}"
        else:
            kb["characters"][name]["backstory"] = new_information
    elif mode == 'overwrite':
        kb["characters"][name]["backstory"] = new_information

    save_knowledge_base(kb, knowledge_path)
    return f"âœ… æˆåŠŸæ›´æ–°è§’è‰² '{name}' çš„èƒŒæ™¯æ•…äº‹"


def update_relationship(character_a: str, character_b: str,
                        new_status: RelationshipStatus,
                        event_summary: str, chapter_evidence: str,
                        current_chapter: int) -> str:
    """
    ç¬¬å››æ­¥ï¼šæ›´æ–°è§’è‰²å…³ç³» (ä¿®å¤ç‰ˆæœ¬)
    ä»…åœ¨å…³ç³»å‘ç”Ÿå˜åŒ–æ—¶æ›´æ–°ï¼Œä½†ä¸å†è‡ªåŠ¨æ›´æ–°èƒŒæ™¯æ•…äº‹
    """
    dotenv.load_dotenv()
    dir1 = os.getenv("MEMORY_ROOT")
    dir2 = os.getenv("CURRENT_PROJECT_ID")

    dir5 = "knowledge_base.json"

    knowledge_path = os.path.join(dir1, dir2, dir5)
    kb = get_knowledge_base(knowledge_path)

    if character_a not in kb["characters"] or character_b not in kb["characters"]:
        return f"âŒ é”™è¯¯ï¼šè§’è‰² '{character_a}' æˆ– '{character_b}' ä¸å­˜åœ¨"
    if character_a == character_b:
        return f"âŒ é”™è¯¯ï¼šä¸èƒ½æ·»åŠ è§’è‰²ä¸è‡ªèº«çš„å…³ç³»"

    # è·å–è§’è‰²Aå½“å‰ä¸è§’è‰²Bçš„å…³ç³»çŠ¶æ€
    current_relationship_dict = kb["characters"][character_a]["relationship"].get(character_b, {})
    current_status = next(iter(current_relationship_dict.keys()), None)

    # --- æ ¸å¿ƒé€»è¾‘ï¼šä»…åœ¨å…³ç³»å‘ç”Ÿå˜åŒ–æ—¶æ‰§è¡Œ ---
    if new_status != current_status:
        # æ„å»ºæ–°çš„å…³ç³»æ¡ç›®
        relationship_entry = {
            new_status: f"{event_summary} (ç¬¬{current_chapter}ç« )"
        }

        # æ›´æ–°è§’è‰²Aå’Œè§’è‰²Bçš„å…³ç³»å­—å…¸
        kb["characters"][character_a]["relationship"][character_b] = relationship_entry
        kb["characters"][character_b]["relationship"][character_a] = relationship_entry

        save_knowledge_base(kb, knowledge_path)
        return f"âœ… å…³ç³»æ›´æ–°ï¼š{character_a} â†” {character_b}ï¼ˆ{new_status}ï¼‰"
    else:
        # å¦‚æœå…³ç³»æ²¡æœ‰å˜åŒ–ï¼Œåˆ™ä¸æ‰§è¡Œä»»ä½•æ“ä½œ
        return f"â„¹ï¸  å…³ç³»æœªå˜ï¼š{character_a} ä¸ {character_b} å·²æ˜¯ '{new_status}'ï¼Œè·³è¿‡æ›´æ–°"


def update_character_backstory(name: str, new_information: str,
                               mode: Literal['append', 'overwrite'] = 'append',
                               current_chapter: Optional[int] = None) -> str:
    """æ›´æ–°è§’è‰²ä¸ªäººèƒŒæ™¯æ•…äº‹

    Args:
        name: è§’è‰²å§“å
        new_information: æ–°çš„èƒŒæ™¯ä¿¡æ¯
        mode: æ›´æ–°æ¨¡å¼ - 'append'è¿½åŠ , 'overwrite'è¦†ç›–
        current_chapter: å½“å‰ç« èŠ‚ï¼ˆå¯é€‰ï¼Œç”¨äºæ·»åŠ ç« èŠ‚æ ‡è®°ï¼‰
    """
    dotenv.load_dotenv()
    dir1 = os.getenv("MEMORY_ROOT")
    dir2 = os.getenv("CURRENT_PROJECT_ID")

    dir5 = "knowledge_base.json"

    knowledge_path = os.path.join(dir1, dir2, dir5)
    kb = get_knowledge_base(knowledge_path)

    if name not in kb["characters"]:
        return f"âŒ é”™è¯¯ï¼šè§’è‰² '{name}' ä¸å­˜åœ¨ï¼Œæ— æ³•æ›´æ–°èƒŒæ™¯æ•…äº‹"

    # æ·»åŠ ç« èŠ‚æ ‡è®°ï¼ˆå¦‚æœæä¾›äº†å½“å‰ç« èŠ‚ï¼‰
    if current_chapter is not None:
        formatted_info = f"ç¬¬{current_chapter}ç« ï¼š{new_information}"
    else:
        formatted_info = new_information

    character = kb["characters"][name]

    if mode == 'append':
        if character["backstory"]:
            character["backstory"] += f"\n{formatted_info}"
        else:
            character["backstory"] = formatted_info
    elif mode == 'overwrite':
        character["backstory"] = formatted_info

    save_knowledge_base(kb, knowledge_path)
    return f"âœ… æˆåŠŸæ›´æ–°è§’è‰² '{name}' çš„ä¸ªäººèƒŒæ™¯æ•…äº‹"


def analyze_relationship_changes(character_interactions: List[Dict],
                                 chapter_text: str, current_chapter: int) -> List[Dict]:
    """ç¬¬ä¸‰æ­¥ï¼šåˆ†æå…³ç³»å˜åŒ– - ä½¿ç”¨è¾“å‡ºè§£æå™¨ç‰ˆæœ¬"""
    tool_calls = []
    if not character_interactions:
        print("â„¹ï¸  æœªè¯†åˆ«åˆ°è§’è‰²äº’åŠ¨ï¼Œæ— éœ€æ›´æ–°å…³ç³»")
        return tool_calls

    # åˆ›å»ºè¾“å‡ºè§£æå™¨
    parser = PydanticOutputParser(pydantic_object=EvidenceText)

    prompt_template = """
ä»»åŠ¡ï¼šä»ä»¥ä¸‹ç« èŠ‚å†…å®¹ä¸­ï¼Œæå–è§’è‰²'{char_a}'å’Œ'{char_b}'äº’åŠ¨çš„å…·ä½“æ–‡æœ¬ç‰‡æ®µã€‚
è¦æ±‚ï¼šä»…è¿”å›æå–çš„æ–‡æœ¬ï¼ˆæœ€å¤š300å­—ç¬¦ï¼‰ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€‚

ç« èŠ‚å†…å®¹ï¼š
{chapter_text}

{format_instructions}
"""

    master_llm = get_evaluation_llm()

    for interaction in character_interactions:
        char_a = interaction.get("character_a", "").strip()
        char_b = interaction.get("character_b", "").strip()
        interaction_type = interaction.get("interaction_type", "é™Œç”Ÿäºº").strip()
        summary = interaction.get("interaction_summary", "æ— æè¿°").strip()

        if not char_a or not char_b:
            continue

        try:
            # ä½¿ç”¨è¾“å‡ºè§£æå™¨æå–è¯æ®
            prompt = PromptTemplate(
                template=prompt_template,
                input_variables=["char_a", "char_b", "chapter_text"],
                partial_variables={"format_instructions": parser.get_format_instructions()}
            )

            chain = prompt | master_llm
            raw_response = chain.invoke({
                "char_a": char_a,
                "char_b": char_b,
                "chapter_text": chapter_text[:1000]  # é™åˆ¶æ–‡æœ¬é•¿åº¦
            })

            # è¿‡æ»¤æ€è€ƒæ ‡ç­¾å¹¶è§£æ
            from helper import filter_think_tags, parse_json_with_filtering
            filtered_content = filter_think_tags(raw_response.content)
            parsed_evidence = parse_json_with_filtering(filtered_content, parser)

            evidence = parsed_evidence.evidence.strip() or "æœªæå–åˆ°å…·ä½“æ–‡æœ¬"

        except Exception as e:
            print(f"--- âŒ è¯æ®æå–å¤±è´¥: {e} ---")
            evidence = "æœªæå–åˆ°å…·ä½“æ–‡æœ¬"

        tool_calls.append({
            "name": "update_relationship",
            "args": {
                "character_a": char_a,
                "character_b": char_b,
                "new_status": interaction_type,
                "event_summary": summary,
                "chapter_evidence": evidence,
                "current_chapter": current_chapter,
            }
        })

    print(f"âœ… ç”Ÿæˆå…³ç³»æ›´æ–°ä»»åŠ¡ï¼š{len(tool_calls)}ä¸ª")
    return tool_calls


def detect_personal_backstory_updates(characters: List[Dict], chapter_text: str, current_chapter: int) -> List[Dict]:
    """æ£€æµ‹å¹¶ç”Ÿæˆä¸ªäººèƒŒæ™¯æ•…äº‹æ›´æ–°ä»»åŠ¡ - ä½¿ç”¨è¾“å‡ºè§£æå™¨ç‰ˆæœ¬"""
    tool_calls = []

    # åˆ›å»ºè¾“å‡ºè§£æå™¨
    parser = PydanticOutputParser(pydantic_object=BackstorySummary)

    prompt_template = """
ä»»åŠ¡ï¼šåˆ†æä»¥ä¸‹ç« èŠ‚å†…å®¹ï¼Œæå–è§’è‰²'{name}'çš„ä¸ªäººèƒŒæ™¯æ•…äº‹ä¿¡æ¯ã€‚
æå–ä¸è§’è‰²ä¸ªäººç›¸å…³ï¼Œæ¯”å¦‚ï¼š
- è§’è‰²çš„ä¸ªäººç»å†ã€å›å¿†
- è§’è‰²çš„å†…å¿ƒç‹¬ç™½ã€æƒ³æ³•
- è§’è‰²çš„æŠ€èƒ½ã€ç‰¹é•¿ã€ä¹ æƒ¯
- è§’è‰²çš„ä¸ªäººç›®æ ‡ã€æ¢¦æƒ³
åŒæ—¶å¯ä»¥å°‘éƒ¨åˆ†åŒ…å«å…¶ä»–è§’è‰²çš„å½±å“,æ¯”å¦‚ï¼š
å…¶ä»–è§’è‰²ä½¿å¾—è¯¥è§’è‰²å‘ç”Ÿäº†å˜åŒ–ç­‰

ç« èŠ‚å†…å®¹ï¼š
{chapter_text}

è¦æ±‚ï¼šè¿”å›ä¸€ä¸ªç®€çŸ­çš„æ€»ç»“ï¼ˆä¸è¶…è¿‡100å­—ï¼‰ï¼Œå¦‚æœæ²¡æœ‰ç›¸å…³çš„ä¸ªäººèƒŒæ™¯ä¿¡æ¯ï¼Œè¿”å›"æ— "

{format_instructions}
"""

    master_llm = get_evaluation_llm()

    for char in characters:
        name = char.get("name", "").strip()
        if not name:
            continue

        try:
            # ä½¿ç”¨è¾“å‡ºè§£æå™¨æå–èƒŒæ™¯æ•…äº‹
            prompt = PromptTemplate(
                template=prompt_template,
                input_variables=["name", "chapter_text"],
                partial_variables={"format_instructions": parser.get_format_instructions()}
            )

            chain = prompt | master_llm
            raw_response = chain.invoke({
                "name": name,
                "chapter_text": chapter_text[:1500]  # é™åˆ¶æ–‡æœ¬é•¿åº¦
            })

            # è¿‡æ»¤æ€è€ƒæ ‡ç­¾å¹¶è§£æ
            from helper import filter_think_tags, parse_json_with_filtering
            filtered_content = filter_think_tags(raw_response.content)
            parsed_summary = parse_json_with_filtering(filtered_content, parser)

            backstory_summary = parsed_summary.summary.strip()

        except Exception as e:
            print(f"--- âŒ èƒŒæ™¯æ•…äº‹æå–å¤±è´¥: {e} ---")
            backstory_summary = "æ— "

        if backstory_summary and backstory_summary != "æ— ":
            tool_calls.append({
                "name": "update_character_backstory",
                "args": {
                    "name": name,
                    "new_information": backstory_summary,
                    "mode": "append",
                    "current_chapter": current_chapter
                }
            })

    return tool_calls

def run_complete_relationship_analysis(chapter_text: str, current_chapter: int = 1):
    """å®Œæ•´çš„è§’è‰²å’Œå…³ç³»åˆ†ææµç¨‹ï¼ˆå·²æ·»åŠ ä¸ªäººèƒŒæ™¯æ•…äº‹æ›´æ–°ï¼‰"""
    print(f"\n" + "=" * 50)
    print(f"ğŸ” å¼€å§‹åˆ†æç¬¬{current_chapter}ç« ")
    print("=" * 50)

    # ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«è§’è‰²
    print("\nğŸ“ ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«ç« èŠ‚ä¸­çš„è§’è‰²...")
    identification_result = identify_characters_in_text(chapter_text, current_chapter)
    characters = identification_result.get("characters", [])
    interactions = identification_result.get("character_interactions", [])

    # ç¬¬äºŒæ­¥ï¼šåˆ›å»º/æ›´æ–°è§’è‰²èŠ‚ç‚¹
    print("\nğŸ‘¤ ç¬¬äºŒæ­¥ï¼šå¤„ç†è§’è‰²èŠ‚ç‚¹ï¼ˆåˆ›å»º/æ›´æ–°ï¼‰...")
    character_tool_calls = []
    for char in characters:
        name = char.get("name", "").strip()
        if not name:
            continue
        character_tool_calls.append({
            "name": "create_character_if_not_exists",
            "args": {
                "name": name,
                "age": char.get("estimated_age"),
                "gender": char.get("gender"),
                "appearance": (char.get("appearance") or "").strip(),
                "traits": [str(t).strip() for t in char.get("traits", []) if str(t).strip()],
                "specialties": [str(t).strip() for t in char.get("specialties", []) if str(t).strip()],
                "hobbies": [str(t).strip() for t in char.get("hobbies", []) if str(t).strip()],
                "occupations": [str(t).strip() for t in char.get("occupations", []) if str(t).strip()],
                "current_chapter": current_chapter,
                "relationship": {}
            }
        })
    print(f"ğŸ“‹ ç”Ÿæˆè§’è‰²æ“ä½œä»»åŠ¡ï¼š{len(character_tool_calls)}ä¸ª")

    # ç¬¬ä¸‰æ­¥ï¼šæ£€æµ‹ä¸ªäººèƒŒæ™¯æ•…äº‹æ›´æ–°
    print("\nğŸ“– ç¬¬ä¸‰æ­¥ï¼šæ£€æµ‹ä¸ªäººèƒŒæ™¯æ•…äº‹æ›´æ–°...")
    backstory_tool_calls = detect_personal_backstory_updates(characters, chapter_text, current_chapter)
    print(f"ğŸ“‹ ç”ŸæˆèƒŒæ™¯æ•…äº‹æ›´æ–°ä»»åŠ¡ï¼š{len(backstory_tool_calls)}ä¸ª")

    # ç¬¬å››æ­¥ï¼šåˆ†æå…³ç³»å˜åŒ–
    print("\nğŸ”— ç¬¬å››æ­¥ï¼šåˆ†æè§’è‰²å…³ç³»å˜åŒ–...")
    relationship_tool_calls = analyze_relationship_changes(
        interactions,
        chapter_text,
        current_chapter
    )
    print(f"ğŸ“‹ ç”Ÿæˆå…³ç³»æ›´æ–°ä»»åŠ¡ï¼š{len(relationship_tool_calls)}ä¸ª")

    all_tool_calls = character_tool_calls + backstory_tool_calls + relationship_tool_calls
    print(f"\nâœ… åˆ†æå®Œæˆï¼šå…±ç”Ÿæˆ {len(all_tool_calls)} ä¸ªæ“ä½œä»»åŠ¡")
    return all_tool_calls


def execute_tool_calls(tool_calls: List[Dict]):
    """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
    available_tools = {
        "create_character_if_not_exists": create_character_if_not_exists,
        "update_character_backstory": update_character_backstory,  # æ·»åŠ è¿™ä¸ª
        "update_relationship": update_relationship
    }

    results = []
    if not tool_calls:
        return results

    print(f"\nğŸ› ï¸  å¼€å§‹æ‰§è¡Œ {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨...")
    for idx, call in enumerate(tool_calls, 1):
        print(f"\n--- ä»»åŠ¡{idx}/{len(tool_calls)}ï¼š{call['name']} ---")
        if call["name"] not in available_tools:
            err_msg = f"âŒ æœªçŸ¥å·¥å…·ï¼š{call['name']}"
            print(err_msg)
            results.append(err_msg)
            continue
        try:
            tool_func = available_tools[call["name"]]
            result = tool_func(**call["args"])
            print(f"âœ… ç»“æœï¼š{result}")
            results.append(result)
        except Exception as e:
            err_msg = f"âŒ æ‰§è¡Œå¤±è´¥ï¼š{str(e)}"
            print(err_msg)
            results.append(err_msg)
    return results


def simulate_user_confirmation_and_execute(tool_calls: List[Dict]):
    """æ¨¡æ‹Ÿç”¨æˆ·ç¡®è®¤å¹¶æ‰§è¡Œ"""
    print("\n" + "=" * 60)
    print(f"ğŸ‘¤ è¯·ç¡®è®¤ä»¥ä¸‹çŸ¥è¯†åº“æ›´æ–°æ“ä½œï¼ˆå…±{len(tool_calls)}ä¸ªï¼‰")
    print("=" * 60)

    if not tool_calls:
        print("â„¹ï¸  æ— å¾…æ‰§è¡Œæ“ä½œï¼Œæ— éœ€ç¡®è®¤")
        return []

    char_ops = [c for c in tool_calls if c["name"] == "create_character_if_not_exists"]
    rel_ops = [c for c in tool_calls if c["name"] == "update_relationship"]

    if char_ops:
        print("\nğŸ“ ã€è§’è‰²æ“ä½œã€‘")
        for op in char_ops:
            args = op["args"]
            print(f"  â€¢ {args['name']}")
            details = []
            if args.get("age"): details.append(f"å¹´é¾„ï¼š{args['age']}")
            if args.get("gender"): details.append(f"æ€§åˆ«ï¼š{args['gender']}")
            if args.get("traits"): details.append(f"æ€§æ ¼ï¼š{', '.join(args['traits'])}")
            if details: print(f"    ï¼ˆ{', '.join(details)}ï¼‰")

    if rel_ops:
        print("\nğŸ”— ã€å…³ç³»æ“ä½œã€‘")
        for op in rel_ops:
            args = op["args"]
            print(f"  â€¢ {args['character_a']} â†” {args['character_b']}")
            print(f"    å…³ç³»ç±»å‹ï¼š{args['new_status']}")
            print(f"    äº‹ä»¶æ‘˜è¦ï¼š{args['event_summary'][:50]}...")
    return execute_tool_calls(tool_calls)


# ================================================================= #
# 5. æµ‹è¯•å‡½æ•°
# ================================================================= #

def character_analysis():
    """æµ‹è¯•è§’è‰²åˆ†æåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•è§’è‰²åˆ†æè¾“å‡ºè§£æ...")

    test_text = """
    æ—å±¿ç«™åœ¨çª—å‰ï¼Œçœ‹ç€å¤–é¢çš„é›¨æ™¯ã€‚ä»–çš„å®¤å‹è‹æ™“æ£ æ­£åœ¨å®¢å…ç”»ç”»ã€‚
    "ä½ ä»Šå¤©çœ‹èµ·æ¥å¿ƒæƒ…ä¸é”™ï¼Œ"è‹æ™“æ£ è¯´é“ï¼Œæ‰‹ä¸­çš„ç”»ç¬”ä¸åœã€‚
    æ—å±¿è½¬è¿‡èº«ï¼Œå¾®å¾®ä¸€ç¬‘ï¼š"æ˜¯å•Šï¼Œä»Šå¤©æ”¶åˆ°äº†ä¸€å®¶å‡ºç‰ˆç¤¾çš„å›å¤ã€‚"
    """

    try:
        result = identify_characters_in_text(test_text, 1)
        print("âœ… è§’è‰²åˆ†ææµ‹è¯•é€šè¿‡")
        print(f"è¯†åˆ«åˆ° {len(result['characters'])} ä¸ªè§’è‰²")
        for char in result['characters']:
            print(f"  - {char['name']}")
    except Exception as e:
        print(f"âŒ è§’è‰²åˆ†ææµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    character_analysis()