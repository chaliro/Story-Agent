import json
import os
import re
from typing import Dict, Any, Optional, List, Tuple

import dotenv
from langchain.chains.llm import LLMChain
from langchain_core.prompts import PromptTemplate
from pydantic import BaseModel, Field
from langchain.output_parsers import PydanticOutputParser

from memory import MemorySystem
from state import StoryState
from utils import get_llm, get_embedding_llm, get_evaluation_llm


# ==================== å®šä¹‰ Pydantic æ¨¡å‹ ====================

class ChapterPlan(BaseModel):
    """ç« èŠ‚è®¡åˆ’æ¨¡å‹"""
    chapter_title: str = Field(description="å¼•äººå…¥èƒœçš„ç« èŠ‚æ ‡é¢˜")
    chapter_outline: str = Field(description="è¯¦ç»†çš„ã€åŒ…å«ä¸»è¦æƒ…èŠ‚ç‚¹çš„ç« èŠ‚å¤§çº²")
    creative_brief: Dict[str, List[str]] = Field(description="åˆ›ä½œæŒ‡ä»¤")


class StorySuggestion(BaseModel):
    """æ•…äº‹å»ºè®®æ¨¡å‹"""
    title: str = Field(description="ç« èŠ‚æ ‡é¢˜")
    story_outline: str = Field(description="æ•´ä¸ªæ•…äº‹çš„å‘å±•è¿‡ç¨‹")
    total_text_style: str = Field(description="å†™ä½œé£æ ¼ã€è¯­æ°”å’Œé‡ç‚¹è¡¨ç°æ‰‹æ³•")


class ChapterSummary(BaseModel):
    """ç« èŠ‚æ‘˜è¦æ¨¡å‹"""
    summary: str = Field(description="ç« èŠ‚å†…å®¹çš„ç®€æ´æ‘˜è¦")


def filter_think_tags(text: str) -> str:
    """
    è¿‡æ»¤æ‰æ–‡æœ¬ä¸­ <think> å’Œ </think> æ ‡ç­¾åŠå…¶ä¹‹é—´çš„å†…å®¹
    """
    if not text:
        return text

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç§»é™¤ <think>...</think> æ ‡ç­¾åŠå…¶å†…å®¹
    filtered_text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)

    # ç§»é™¤å¯èƒ½æ®‹ç•™çš„ <think> æˆ– </think> æ ‡ç­¾ï¼ˆä¸å®Œæ•´çš„æƒ…å†µï¼‰
    filtered_text = re.sub(r'<think>|</think>', '', filtered_text)

    # ç§»é™¤å¤šä½™çš„ç©ºè¡Œå’Œç©ºç™½å­—ç¬¦
    filtered_text = re.sub(r'\n\s*\n', '\n\n', filtered_text).strip()

    return filtered_text


def parse_json_with_filtering(text: str, parser) -> Any:
    """
    å…ˆè¿‡æ»¤æ‰æ€è€ƒæ ‡ç­¾ï¼Œç„¶åå°è¯•è§£æJSON
    """
    try:
        # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
        return parser.parse(text)
    except Exception as e:
        # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•è¿‡æ»¤æ€è€ƒæ ‡ç­¾åå†è§£æ
        filtered_text = filter_think_tags(text)
        try:
            return parser.parse(filtered_text)
        except Exception as e2:
            # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', filtered_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                try:
                    return parser.parse(json_str)
                except Exception as e3:
                    raise e3
            raise e2


def get_best_draft(state: StoryState) -> Dict[str, Any]:
    print("--- ğŸ“– Get Best Chapter: Selecting best version.. ---")
    # --- å…³é”®ä¿®æ”¹ï¼šå°†æœ€åä¸€ä¸ªç‰ˆæœ¬ä¹ŸåŠ å…¥å€™é€‰åˆ—è¡¨ ---
    current_versions = state.get('chapter_versions', [])
    last_decision = state.get('committee_decision')
    last_draft = state.get('revised_draft')

    if last_decision and last_draft:
        scores = last_decision.get('dimension_scores', {})
        numeric_scores = [s['score'] for s in scores.values() if isinstance(s.get('score'), (int, float))]
        avg_score = sum(numeric_scores) / len(numeric_scores) if numeric_scores else 0
        current_versions.append({
            "draft": last_draft,
            "scores": scores,
            "average_score": avg_score
        })

    if not current_versions:
        print("--- âŒ Error: No chapter versions found to publish. ---")
        # å›é€€åˆ°ä½¿ç”¨æœ€åçš„è‰ç¨¿
        best_draft = last_draft or "Error: No content available."
    else:
        # --- å…³é”®ä¿®æ”¹ï¼šæ‰¾åˆ°åˆ†æ•°æœ€é«˜çš„ç‰ˆæœ¬ ---
        best_version = max(current_versions, key=lambda x: x['average_score'])
        best_draft = best_version['draft']
        best_score = best_version['average_score']
        print(f"--- ğŸ† Best version selected with average score: {best_score:.2f} ---")
    return {"final_chapter": best_draft}


def publish_chapter(state: StoryState, best_draft: str) -> StoryState:
    """
    å‘å¸ƒç« èŠ‚ Agent - v2.0
    - v2.0: ä»æ‰€æœ‰ä¿®è®¢ç‰ˆæœ¬ä¸­é€‰æ‹©å¹³å‡åˆ†æœ€é«˜çš„è¿›è¡Œå‘å¸ƒã€‚
    """
    print("--- ğŸ“– Publish Chapter: Selecting best version and publishing to memory... ---")

    chapter_index = state['current_chapter_index']
    chapter_title = state['chapter_title']

    # ä½¿ç”¨è¾“å‡ºè§£æå™¨ç”Ÿæˆæ‘˜è¦
    print("--- ğŸ“ Generating chapter summary for the best version... ---")
    summary = generate_chapter_summary(chapter_title, best_draft)

    memory_dir = get_memory_path()
    memory = MemorySystem.load(memory_dir, get_embedding_llm())

    # å°†æœ€ä½³ç« èŠ‚æ·»åŠ åˆ°è®°å¿†ç³»ç»Ÿ
    memory.add_chapter(
        chapter_index=chapter_index,
        chapter_title=chapter_title,
        full_text=best_draft,
        summary=summary
    )

    # æ›´æ–°å†å²è®°å½•
    full_text_history = state.get('full_text_history', []) + [best_draft]
    summary_history = state.get('summary_history', []) + [summary]

    print(f"--- âœ… Successfully published Chapter {chapter_index}: '{chapter_title}' ---")
    print(f"Summary: {summary[:100]}...")
    state["published_chapter"] = best_draft
    state["full_text_history"] = full_text_history
    state["summary_history"] = summary_history
    current_chapter_index = state["current_chapter_index"]
    state["current_chapter_index"] = current_chapter_index + 1

    return state


def generate_chapter_summary(chapter_title: str, chapter_content: str) -> str:
    """ä½¿ç”¨è¾“å‡ºè§£æå™¨ç”Ÿæˆç« èŠ‚æ‘˜è¦"""
    parser = PydanticOutputParser(pydantic_object=ChapterSummary)

    prompt_template = """
è¯·ä¸ºä»¥ä¸‹ç« èŠ‚å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆä¸è¶…è¿‡150å­—ï¼‰ï¼š

**ç« èŠ‚æ ‡é¢˜**: {chapter_title}
**ç« èŠ‚å†…å®¹**: {chapter_content}

{format_instructions}
"""

    llm = get_evaluation_llm()

    try:
        prompt = PromptTemplate(
            template=prompt_template,
            input_variables=["chapter_title", "chapter_content"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )

        chain = prompt | llm
        raw_response = chain.invoke({
            "chapter_title": chapter_title,
            "chapter_content": chapter_content
        })

        # è¿‡æ»¤æ€è€ƒæ ‡ç­¾å¹¶è§£æ
        filtered_content = filter_think_tags(raw_response.content)
        parsed_summary = parse_json_with_filtering(filtered_content, parser)

        return parsed_summary.summary

    except Exception as e:
        print(f"--- âŒ Error generating summary: {e} ---")
        # å›é€€åˆ°ç®€å•çš„æˆªæ–­æ‘˜è¦
        return chapter_content[:147] + "..." if len(chapter_content) > 150 else chapter_content


def update_json_with_dict(file_path, updates):
    """
    æ ¹æ®æä¾›çš„å­—å…¸æ›´æ–° JSON æ–‡ä»¶ä¸­çš„å­—æ®µä¿¡æ¯ã€‚
    åªæ›´æ–°å­—å…¸ä¸­å­˜åœ¨äº JSON æ–‡ä»¶ä¸­çš„é”®ï¼Œè·³è¿‡ä¸å­˜åœ¨çš„é”®ã€‚
    æ”¯æŒåµŒå¥—å­—å…¸å’Œåˆ—è¡¨çš„æ›´æ–°ã€‚

    Args:
        file_path (str): JSON æ–‡ä»¶çš„è·¯å¾„
        updates (dict): åŒ…å«è¦æ›´æ–°çš„å­—æ®µåŠå…¶æ–°å€¼çš„å­—å…¸
    """
    try:
        # è¯»å– JSON æ–‡ä»¶
        with open(file_path, 'r', encoding='utf-8') as file:
            data = json.load(file)  # åŠ è½½ JSON æ•°æ®

        # å®šä¹‰ä¸€ä¸ªé€’å½’å‡½æ•°æ¥æ›´æ–°åµŒå¥—å­—å…¸


        def update_nested_dict(target_dict, updates_dict):
            for key, value in updates_dict.items():
                if key in target_dict:
                    # å¦‚æœå€¼æ˜¯å­—å…¸ï¼Œåˆ™é€’å½’æ›´æ–°
                    if isinstance(target_dict[key], dict) and isinstance(value, dict):
                        update_nested_dict(target_dict[key], value)
                    # å¦‚æœå€¼æ˜¯åˆ—è¡¨ï¼Œåˆ™æ›´æ–°æ•´ä¸ªåˆ—è¡¨
                    elif isinstance(target_dict[key], list) and isinstance(value, list):
                        target_dict[key] = value
                    # å¦åˆ™ç›´æ¥æ›´æ–°å€¼
                    else:
                        target_dict[key] = value
                else:
                    print(f"è·³è¿‡æ›´æ–°ï¼šé”® '{key}' ä¸å­˜åœ¨äº JSON æ–‡ä»¶ä¸­ã€‚")

        # æ›´æ–°å­—æ®µå€¼
        update_nested_dict(data, updates)

        # å†™å› JSON æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as file:
            json.dump(data, file, indent=4, ensure_ascii=False)  # æ ¼å¼åŒ–å†™å…¥

        print("JSON æ–‡ä»¶å·²æˆåŠŸæ›´æ–°å­˜åœ¨çš„é”®ï¼")

    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šæ–‡ä»¶ '{file_path}' ä¸å­˜åœ¨ï¼")
    except json.JSONDecodeError:
        print(f"é”™è¯¯ï¼šæ–‡ä»¶ '{file_path}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ JSON æ–‡ä»¶ï¼")
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯ï¼š{e}")


def initial_memory(json_path: str, memory_path: str):
    embeddings = get_embedding_llm()
    memory = MemorySystem.load(memory_path, embedding_model=embeddings)
    with open(json_path, "r", encoding="utf-8") as f:
        story_data = json.load(f)
    story_data["memory"] = memory


def get_memory_path():
    dotenv.load_dotenv()
    dir1 = os.getenv("MEMORY_ROOT")
    dir2 = os.getenv("CURRENT_PROJECT_ID")
    memory_path = os.path.join(dir1, dir2)
    return memory_path


# (ç¡®ä¿è¿™åœ¨ planned å‡½æ•°æ‰€åœ¨çš„å•å…ƒæ ¼)
def planned(user_input: str, json_path: str, memory_path: str, memory_system: Optional[MemorySystem] = None):
    """
    ç« èŠ‚è§„åˆ’æ ¸å¿ƒå¼•æ“å‡½æ•° V2.1ã€‚
    - æ¥å—ä¸€ä¸ªå¯é€‰çš„ memory_system å®ä¾‹ä»¥é¿å…é‡å¤åŠ è½½ã€‚
    """
    STORY_JSON_FILE = json_path
    MEMORY_DIR = memory_path
    print(json_path)
    print(memory_path)
    print("\n" + "=" * 50)
    print("ğŸš€ Executing Chapter Planning Function...")
    print(f"User Input: \"{user_input}\"")
    print("=" * 50)

    try:
        # åŠ è½½ story_data
        with open(STORY_JSON_FILE, "r", encoding="utf-8") as f:
            story_data = json.load(f)

        title = story_data.get("title", "æœªå‘½åæ•…äº‹")
        story_outline = story_data.get("story_outline", "æ— å¤§çº²")
        current_chapter_index = story_data.get("current_chapter_index", 0)
        chapter_data = {
            "chapter_title": story_data.get("chapter_title"),
            "chapter_outline": story_data.get("chapter_outline"),
            "creative_brief": story_data.get("creative_brief"),
        }
        # ä¸Šä¸€ç« å†…å®¹å›é¡¾
        full_text_history = story_data["full_text_history"]
        previous_chapter_section = "### ä¸Šä¸€ç« å†…å®¹å›é¡¾\n(è¿™æ˜¯æ•…äº‹çš„ç¬¬ä¸€ç« ï¼Œæ²¡æœ‰å‰æ–‡ã€‚)"
        if full_text_history:
            previous_chapter_section = f"""### ä¸Šä¸€ç« å†…å®¹å›é¡¾ (è¯·ç¡®ä¿ä½ çš„åˆ›ä½œä¸ä¹‹æ— ç¼è¡”æ¥)
        {full_text_history[-1]}
        """
        summary_history = story_data["summary_history"]
        # æ–°å¢ï¼šä¸Šä¸Šä¸Šç« çš„æ€»ç»“å›é¡¾
        three_chapters_back_summary = ""
        if len(summary_history) >= 3:
            three_chapters_back_summary = f"""### å‰ä¸‰ç« æ€»ç»“å›é¡¾ (æä¾›æ›´ä¹…è¿œçš„æ•…äº‹èƒŒæ™¯)
        {summary_history[-3]}
        """
        chapter_json = json.dumps(chapter_data, indent=4, ensure_ascii=False)

        # --- ã€å…³é”®ä¿®æ”¹ç‚¹ã€‘ ---
        # å¦‚æœæ²¡æœ‰ä¼ å…¥ memory_system å®ä¾‹ï¼Œåˆ™åŠ è½½å®ƒ
        if memory_system is None:
            print("--- No MemorySystem instance provided, loading from disk... ---")
            embeddings = get_embedding_llm()
            memory = MemorySystem.load(MEMORY_DIR, embedding_model=embeddings)
        else:
            print("--- Using provided MemorySystem instance. ---")
            memory = memory_system

        # ... (åç»­çš„æ£€ç´¢å’Œè§„åˆ’é€»è¾‘ä¿æŒä¸å˜) ...
        print("\n2. Preparing and executing vector database retrieval...")
        retrieval_query = user_input
        retrieved_context = memory.retrieve_context_for_writer(query=retrieval_query)
        print("âœ… Retrieval complete.")

        print("\n3. Constructing prompt and calling LLM for chapter planning...")

        # ä½¿ç”¨è¾“å‡ºè§£æå™¨
        parser = PydanticOutputParser(pydantic_object=ChapterPlan)

        prompt_template = """
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„å°è¯´ä¸»ç¼–ï¼Œè´Ÿè´£ä¸ºæ•…äº‹çš„å½“å‰ç« èŠ‚åˆ¶å®šè¯¦ç»†çš„åˆ›ä½œè®¡åˆ’ã€‚

### æ•…äº‹èƒŒæ™¯
- **æ•…äº‹æ ‡é¢˜**: {title}
- **æ•…äº‹æ€»å¤§çº²**: {story_outline}
- **ä¸Šä¸€ç« èŠ‚å†…å®¹**: {previous_chapter_section}
- **å‰ä¸‰ç« èŠ‚çš„æ‘˜è¦**: {three_chapters_back_summary}
### ä¸Šä¸‹æ–‡ä¸æŒ‡ä»¤
1. **ä»è®°å¿†åº“æ£€ç´¢åˆ°çš„ç›¸å…³å†å²æƒ…èŠ‚**:\n{retrieved_context}
2. **ç°åœ¨å·²æœ‰çš„åˆ›ä½œæŒ‡ä»¤**:\n{chapter_json}
3. **ç”¨æˆ·çš„æœ€æ–°æŒ‡ä»¤ (æœ€é‡è¦)**:\n\"{user_input}\"

### ä½ çš„ä»»åŠ¡
è¯·ç»¼åˆä»¥ä¸Šæ‰€æœ‰ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯**ç”¨æˆ·çš„æœ€æ–°æŒ‡ä»¤**ï¼Œä¸ºå½“å‰ç« èŠ‚ï¼ˆç¬¬ {current_chapter_index} ç« ï¼‰ç”Ÿæˆä¸€ä»½æœ€ç»ˆçš„ã€ä¼˜åŒ–è¿‡çš„åˆ›ä½œè®¡åˆ’ã€‚
ä½ ç”Ÿæˆçš„chapter_outlineåº”è¯¥åœ¨300å­—å·¦å³

{format_instructions}
"""

        llm = get_llm()

        prompt = PromptTemplate(
            template=prompt_template,
            input_variables=["title", "story_outline", "retrieved_context", "chapter_json",
                             "user_input", "current_chapter_index", "previous_chapter_section", "three_chapters_back_summary"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )

        chain = prompt | llm
        raw_response = chain.invoke({
            "title": title,
            "story_outline": story_outline,
            "retrieved_context": retrieved_context,
            "chapter_json": chapter_json,
            "user_input": user_input,
            "current_chapter_index": current_chapter_index,
            "previous_chapter_section": previous_chapter_section,
            "three_chapters_back_summary": three_chapters_back_summary
        })

        # è¿‡æ»¤æ€è€ƒæ ‡ç­¾å¹¶è§£æ
        filtered_content = filter_think_tags(raw_response.content)
        new_plan = parse_json_with_filtering(filtered_content, parser)

        # æ›´æ–° JSON æ–‡ä»¶

        story_data["chapter_title"] = new_plan.chapter_title
        story_data["chapter_outline"] = new_plan.chapter_outline
        story_data["creative_brief"] = new_plan.creative_brief
        story_data["committee_decision"] = None

        with open(STORY_JSON_FILE, "w", encoding="utf-8") as f:
            json.dump(story_data, f, ensure_ascii=False, indent=4)

        print(f"âœ… '{STORY_JSON_FILE}' updated successfully for Chapter {story_data['current_chapter_index']}.")

    except Exception as e:
        print(f"âŒ åœ¨è§„åˆ’å‡½æ•°ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")


def put_chapter(chapter_title: str, chapter_content: str, chapter_path: str):
    """
        ä¿å­˜ç« èŠ‚å†…å®¹åˆ°JSONæ–‡ä»¶ä¸­

        å‚æ•°:
            chapter_title (str): ç« èŠ‚æ ‡é¢˜
            chapter_content (str): ç« èŠ‚å†…å®¹
            chapter_path (str): JSONæ–‡ä»¶è·¯å¾„
        """
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if os.path.exists(chapter_path):
        with open(chapter_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    else:
        # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºå¹¶åˆå§‹åŒ–
        data = {'current_index': 1}
    key = f"ç¬¬{data['current_index']}ç«  {chapter_title}"
    data[key] = chapter_content

    # current_indexåŠ 1
    data['current_index'] += 1

    # ä¿å­˜å›æ–‡ä»¶
    with open(chapter_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)


def get_all_chapter(chapter_path: str) -> Dict[str, str]:
    with open(chapter_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data


def finalize_chapter_and_save_state(final_state: StoryState, json_path: str, memory_path: str):
    """
    å·¥ä½œæµåå¤„ç†å‡½æ•°ã€‚
    - å°†å·¥ä½œæµçš„æœ€ç»ˆçŠ¶æ€è¿›è¡Œæ¸…ç†å’Œæ•´åˆã€‚
    - ä¿å­˜æ›´æ–°åçš„MemorySystemã€‚
    - å°†æŒä¹…åŒ–çš„æ•…äº‹çŠ¶æ€å†™å›JSONæ–‡ä»¶ï¼Œä¸ºä¸‹ä¸€æ¬¡è§„åˆ’åšå‡†å¤‡ã€‚
    """
    print("\n" + "=" * 50)
    print("ğŸš€ Executing Post-Workflow Finalization...")
    print(f"Updating state in '{json_path}'")
    print("=" * 50)

    try:
        # 1. éªŒè¯æœ€ç»ˆçŠ¶æ€æ˜¯å¦æœ‰æ•ˆ
        if not final_state or not final_state.get("published_chapter"):
            print("âŒ é”™è¯¯: æœ€ç»ˆçŠ¶æ€æ— æ•ˆæˆ–ç« èŠ‚æœªå‘å¸ƒï¼Œæ— æ³•è¿›è¡Œæœ€ç»ˆå¤„ç†ã€‚")
            return

        memory = MemorySystem.load(memory_path, get_embedding_llm())
        # 3. å‡†å¤‡è¦æŒä¹…åŒ–åˆ°JSONçš„æ–°çŠ¶æ€
        # è¿™äº›æ˜¯éœ€è¦è·¨ç« èŠ‚ä¿ç•™çš„å…³é”®ä¿¡æ¯
        persistent_story_data = {
            "title": final_state.get("title"),
            "story_outline": final_state.get("story_outline"),
            "current_chapter_index": final_state.get("current_chapter_index"),
            "full_text_history": final_state.get("full_text_history"),
            "summary_history": final_state.get("summary_history"),
            "committee_decision": final_state.get("committee_decision"),  # ä¿å­˜è¿™æ¬¡çš„å†³ç­–ï¼Œä¸ºä¸‹ä¸€æ¬¡è§„åˆ’æä¾›å‚è€ƒ

            # --- é‡ç½®æ‰€æœ‰ä¸´æ—¶å­—æ®µï¼Œä¸ºä¸‹ä¸€ç« åšå‡†å¤‡ ---
            "chapter_title": "",
            "chapter_outline": "",
            "creative_brief": {
                "narrative_goals": [
                ],
                "character_focus": [
                ],
                "thematic_elements": [
                ],
                "structural_requirements": [
                ]
            },
            "initial_draft": None,
            "revised_draft": None,
            "rewrite_attempts": 0,
            "suggestions": [],
            "expert_evaluations": [],
            "published_chapter": None,
            "agent_flags": {},
            "required_agents": [],
            "chapter_versions": [],
            "revision_brief": None,
            "final_chapter": [],
        }
        print("âœ… Prepared persistent state for the next chapter.")

        # 4. å°†æ–°çŠ¶æ€å†™å…¥JSONæ–‡ä»¶
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(persistent_story_data, f, ensure_ascii=False, indent=4)

        print(f"âœ… Successfully updated '{json_path}'. The system is ready for the next chapter planning.")
        print("=" * 50)
        print("ğŸ‰ Finalization complete.")
        print("=" * 50)

    except KeyError as e:
        print(f"âŒ é”™è¯¯: æœ€ç»ˆçŠ¶æ€ä¸­ç¼ºå°‘å¿…è¦çš„é”®: {e}")
    except Exception as e:
        print(f"âŒ åœ¨åå¤„ç†å‡½æ•°ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def _parse_llm_response(response: str) -> Dict[str, str]:
    """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æLLMçš„ç»“æ„åŒ–è¾“å‡ºï¼Œä»¥æé«˜å¥å£®æ€§ã€‚"""
    response = response.strip()
    parsed_suggestions = {"title": "", "story_outline": "", "total_text_style": ""}

    try:
        title_match = re.search(r"title:\s*(.*?)\s*story_outline:", response, re.DOTALL)
        if title_match:
            parsed_suggestions["title"] = title_match.group(1).strip()

        outline_match = re.search(r"story_outline:\s*(.*?)\s*total_text_style:", response, re.DOTALL)
        if outline_match:
            parsed_suggestions["story_outline"] = outline_match.group(1).strip()

        style_match = re.search(r"total_text_style:\s*(.*)", response, re.DOTALL)
        if style_match:
            parsed_suggestions["total_text_style"] = style_match.group(1).strip()
    except Exception as e:
        print(f"[é”™è¯¯] è§£æLLMå“åº”æ—¶å‡ºé”™: {e}")
        # åœ¨è§£æå¤±è´¥æ—¶ï¼Œå°†åŸå§‹å“åº”æ”¾å…¥å…¶ä¸­ä¸€ä¸ªå­—æ®µï¼Œä»¥ä¾¿è°ƒè¯•
        parsed_suggestions["raw_response"] = response

    return parsed_suggestions


def get_ai_suggestions(user_input: str) -> Dict[str, str]:
    """
    æ ¹æ®ç”¨æˆ·è¾“å…¥ï¼Œç”ŸæˆAIå»ºè®®çš„å°è¯´æ ‡é¢˜ã€å¤§çº²å’Œé£æ ¼æŒ‡å¯¼ã€‚

    Args:
        user_input: ç”¨æˆ·æä¾›çš„åˆ›ä½œéœ€æ±‚ã€‚

    Returns:
        åŒ…å«å»ºè®®å­—å…¸çš„å…ƒç»„ã€‚
    """
    print(f"\n--- æ”¶åˆ°ç”¨æˆ·éœ€æ±‚: \"{user_input}\" ---")
    print("--- ğŸ¤– æ­£åœ¨ç”ŸæˆAIåˆ›ä½œå»ºè®®... ---")

    # ä½¿ç”¨è¾“å‡ºè§£æå™¨
    parser = PydanticOutputParser(pydantic_object=StorySuggestion)

    prompt_template = """
ä½ æ˜¯ä¸€ä¸ªå°è¯´ç”ŸæˆåŠ©æ‰‹ï¼Œæ ¹æ®ç”¨æˆ·è¾“å…¥ç”ŸæˆAIå»ºè®®çš„æ ‡é¢˜ã€å¤§çº²å’Œé£æ ¼æŒ‡å¯¼ã€‚

è¯·æ ¹æ®ç”¨æˆ·çš„åˆ›ä½œéœ€æ±‚ï¼Œç”Ÿæˆå°è¯´ç« èŠ‚çš„å»ºè®®æ ‡é¢˜ã€è¯¦ç»†å¤§çº²å’Œé£æ ¼æŒ‡å¯¼ã€‚

ç”¨æˆ·éœ€æ±‚ï¼š{user_input}

{format_instructions}
"""

    llm = get_llm()

    try:
        prompt = PromptTemplate(
            template=prompt_template,
            input_variables=["user_input"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )

        chain = prompt | llm
        raw_response = chain.invoke({"user_input": user_input})

        # è¿‡æ»¤æ€è€ƒæ ‡ç­¾å¹¶è§£æ
        filtered_content = filter_think_tags(raw_response.content)
        parsed_suggestion = parse_json_with_filtering(filtered_content, parser)

        return parsed_suggestion.model_dump()

    except Exception as e:
        print(f"--- âŒ Error generating AI suggestions: {e} ---")
        # å›é€€åˆ°åŸå§‹æ–¹æ³•
        return get_ai_suggestions_fallback(user_input)


def get_ai_suggestions_fallback(user_input: str) -> Dict[str, str]:
    """å›é€€æ–¹æ³•ï¼šä½¿ç”¨åŸå§‹çš„JSONè§£ææ–¹å¼"""
    prompt_template = f"""
ä½ æ˜¯ä¸€ä¸ªå°è¯´ç”ŸæˆåŠ©æ‰‹ï¼Œæ ¹æ®ç”¨æˆ·è¾“å…¥ç”ŸæˆAIå»ºè®®çš„æ ‡é¢˜ã€å¤§çº²å’Œé£æ ¼æŒ‡å¯¼ã€‚

è¯·æ ¹æ®ç”¨æˆ·çš„åˆ›ä½œéœ€æ±‚ï¼Œç”Ÿæˆå°è¯´ç« èŠ‚çš„å»ºè®®æ ‡é¢˜ã€è¯¦ç»†å¤§çº²å’Œé£æ ¼æŒ‡å¯¼ï¼Œå¹¶ä»¥å­—å…¸æ ¼å¼è¿”å›ã€‚

ç”¨æˆ·éœ€æ±‚ï¼š{user_input}

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- å­—å…¸ä¸­å¿…é¡»åŒ…å«ä»¥ä¸‹é”®å€¼å¯¹ï¼š
  - 'title': æä¾›1ä¸ªæœ€ç¬¦åˆéœ€æ±‚çš„ç« èŠ‚æ ‡é¢˜ï¼ˆå­—ç¬¦ä¸²ç±»å‹ï¼‰
  - 'story_outline': ä½¿ç”¨ä¸€æ®µè¯ä»‹ç»æ•´ä¸ªæ•…äº‹çš„å‘å±•è¿‡ç¨‹ï¼ˆå­—ç¬¦ä¸²ç±»å‹ï¼‰
  - 'total_text_style': æè¿°é€‚åˆè¯¥ç« èŠ‚çš„å†™ä½œé£æ ¼ã€è¯­æ°”å’Œé‡ç‚¹è¡¨ç°æ‰‹æ³•ï¼ˆå­—ç¬¦ä¸²ç±»å‹ï¼‰

ç¤ºä¾‹ï¼š
{{
  "title": "åˆé‡çš„å’–å•¡é¦†",
  "story_outline": "æ•…äº‹å‘ç”Ÿåœ¨ä¸€ä¸ªæ¸©é¦¨çš„å’–å•¡é¦†ï¼Œå¥³ä¸»è§’æ—é›¨æ˜¯ä¸€ä¸ªçƒ­çˆ±å’–å•¡ä¸ä¹¦ç±çš„å¹´è½»ä½œå®¶ï¼Œå› ä¸€æ¬¡å¶ç„¶çš„æœºä¼šï¼Œåœ¨è¿™é‡Œé‚‚é€…äº†ç”·ä¸»è§’èµµæ™¨ï¼Œä¸€ä¸ªåˆšåˆšå›å›½çš„æ‘„å½±å¸ˆã€‚ä¸¤äººåœ¨å’–å•¡é¦†çš„ç¬¬ä¸€æ¬¡ç›¸é‡å……æ»¡äº†ç«èŠ±ï¼Œæ—é›¨è¢«èµµæ™¨çš„å¹½é»˜ä¸æ‰åå¸å¼•ï¼Œè€Œèµµæ™¨ä¹Ÿå¯¹æ—é›¨çš„ç‹¬ç«‹ä¸çƒ­æƒ…å°è±¡æ·±åˆ»ã€‚éšç€æ—¶é—´çš„æ¨ç§»ï¼Œä¸¤äººå¼€å§‹é¢‘ç¹è§é¢ï¼Œåˆ†äº«å½¼æ­¤çš„æ¢¦æƒ³ä¸ç”Ÿæ´»ã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œä»–ä»¬ä¸ä»…å½¼æ­¤æ‰¶æŒï¼Œåœ¨å„è‡ªçš„äº‹ä¸šä¸Šä¹Ÿå–å¾—äº†è¿›å±•ã€‚ç„¶è€Œï¼Œéšç€èµµæ™¨äº‹ä¸šçš„å‘å±•ï¼Œé¢ä¸´çš„é€‰æ‹©ä½¿å¾—ä¸¤äººçš„å…³ç³»å˜å¾—ç´§å¼ ï¼Œæ—é›¨éœ€è¦é¢å¯¹è‡ªå·±çš„æƒ…æ„Ÿä¸æ¢¦æƒ³çš„æŠ‰æ‹©ï¼Œæœ€ç»ˆä¸¤äººèƒ½å¦åœ¨äº‹ä¸šä¸çˆ±æƒ…ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ï¼Œæˆä¸ºäº†æ•…äº‹çš„æ ¸å¿ƒå†²çªã€‚",
  "total_text_style": "å†™ä½œé£æ ¼ï¼šä»¥ç»†è…»è€Œå¯Œæœ‰è¯—æ„çš„è¯­è¨€æç»˜éƒ½å¸‚ç”Ÿæ´»çš„ç¾å¥½ä¸å¤æ‚ï¼ŒæŠ’æƒ…è€Œä¸å¤±çœŸå®ã€‚ä½¿ç”¨ä¸°å¯Œçš„æ„è±¡ï¼Œå¦‚å’–å•¡çš„é¦™æ°”ã€ä¹¦é¡µçš„ç¿»åŠ¨ç­‰ï¼Œæ¥ä¼ è¾¾äººç‰©å†…å¿ƒçš„æƒ…æ„Ÿæ³¢åŠ¨ã€‚è¯­æ°”æ¸©æš–è€Œäº²åˆ‡ï¼Œæ—¶è€Œå¸¦æœ‰æ·¡æ·¡çš„å¿§ä¼¤ï¼Œå¼ºè°ƒäººç‰©ä¹‹é—´çš„æƒ…æ„Ÿäº¤æµä¸å†…å¿ƒæŒ£æ‰ã€‚å™è¿°ä¸­èå…¥ç»†è…»çš„å¿ƒç†æå†™ï¼Œå±•ç°äººç‰©çš„æˆé•¿ä¸å˜åŒ–ï¼ŒåŒæ—¶é€šè¿‡å¯¹è¯ä¸æ—¥å¸¸ç»†èŠ‚æ¥æ¨åŠ¨æƒ…èŠ‚å‘å±•ï¼Œä¿æŒæ•…äº‹çš„æµç•…æ€§ä¸çœŸå®æ„Ÿã€‚æ•…äº‹èšç„¦åœ¨çˆ±æƒ…ä¸æ¢¦æƒ³çš„äº¤ç»‡ä¸­ï¼Œè®©è¯»è€…åœ¨å¹³å‡¡çš„ç”Ÿæ´»ä¸­æ„Ÿå—åˆ°çˆ±çš„åŠ›é‡ä¸å¸Œæœ›çš„å…‰èŠ’ã€‚"
}}

è¯·ç›´æ¥è¿”å›å­—å…¸æ ¼å¼å†…å®¹ï¼Œä¸è¦æ·»åŠ å¤šä½™çš„æ–‡å­—æˆ–è§£é‡Šã€‚
"""

    llm = get_llm()
    response = llm.invoke(prompt_template).content

    try:
        story_dict = json.loads(response)
        return story_dict
    except json.JSONDecodeError:
        print("--- âŒ Failed to parse JSON, using regex fallback ---")
        return _parse_llm_response(response)


def route(state: StoryState) -> StoryState:  # è¿”å›ç±»å‹åº”è¯¥æ˜¯ StoryState
    # ç›´æ¥åœ¨ä¼ å…¥çš„ state å¯¹è±¡ä¸Šåˆ›å»º agent_flags é”®
    state["agent_flags"] = {
        "emotional_reader_agent": 0,
        "rhythm_reader_agent": 0,
        "immersion_reader_agent": 0,
        "structural_novelist_agent": 0,
        "foreshadowing_novelist_agent": 0
    }
    if state['revised_draft'] is not None:
        state['initial_draft'] = state['revised_draft']
        state['revised_draft'] = None
    # æ ¹æ® required_agents æ›´æ–° flags
    for k in state["required_agents"]:
        state["agent_flags"][k] = 1

    # è¿”å›è¢«ä¿®æ”¹åçš„ state å¯¹è±¡
    return state


def decide_to_publish_or_rewrite(state: StoryState) -> str:
    """
    ä»…æ ¹æ®éœ€è¦é‡å†™çš„Agentåˆ—è¡¨å’Œé‡å†™æ¬¡æ•°å†³å®šä¸‹ä¸€æ­¥æ“ä½œã€‚
    """
    print("--- ğŸ” å†³ç­–ä¸­ï¼šå‘å¸ƒæˆ–é‡å†™... ---")
    rewrite_attempts = state.get('rewrite_attempts', 0)
    required_agents = state.get("required_agents", [])

    # å¦‚æœéœ€è¦é‡å†™çš„agentåˆ—è¡¨ä¸ä¸ºç©ºï¼Œå¹¶ä¸”é‡å†™æ¬¡æ•°å°äº3æ¬¡ï¼Œåˆ™é€‰æ‹©é‡å†™
    if required_agents and rewrite_attempts < 1:
        print(f"--- è£å†³ï¼šéœ€è¦é‡å†™ (å½“å‰å°è¯•æ¬¡æ•°: {rewrite_attempts}) ---")
        return "rewrite_chapter"
    else:
        # å¦åˆ™ï¼Œç›´æ¥å‘å¸ƒï¼ˆåŒ…æ‹¬é‡å†™è¶…è¿‡3æ¬¡è¢«å¼ºåˆ¶å‘å¸ƒçš„æƒ…å†µï¼‰
        print("--- è£å†³ï¼šå‘å¸ƒç« èŠ‚ ---")
        return "publish_chapter"


def prepare_for_rewrite(state: StoryState) -> dict:
    """
    åœ¨æ¯æ¬¡é‡å†™å¾ªç¯å¼€å§‹å‰ï¼Œæ›´æ–°çŠ¶æ€ã€‚
    - v2.0: ä¿å­˜å½“å‰è‰ç¨¿åŠå…¶è¯„åˆ†ï¼Œå¹¶ä¸ºä¸‹ä¸€è½®å»ºè®®è€…æä¾›é’ˆå¯¹æ€§ç®€æŠ¥ã€‚
    """
    rewrite_attempts = state.get('rewrite_attempts', 0) + 1

    # --- å…³é”®ä¿®æ”¹ï¼šä¿å­˜å½“å‰ç‰ˆæœ¬åŠå…¶è¯„åˆ† ---
    current_versions = state.get('chapter_versions', [])
    last_decision = state.get('committee_decision')
    last_draft = state.get('revised_draft')

    revision_brief_for_next_loop = {}
    if last_decision and last_draft:
        scores = last_decision.get('dimension_scores', {})
        # è®¡ç®—å¹³å‡åˆ†
        numeric_scores = [s['score'] for s in scores.values() if isinstance(s.get('score'), (int, float))]
        avg_score = sum(numeric_scores) / len(numeric_scores) if numeric_scores else 0

        # å°†æ­¤ç‰ˆæœ¬å­˜å…¥å†å²è®°å½•
        current_versions.append({
            "draft": last_draft,
            "scores": scores,
            "average_score": avg_score
        })
        print(f"--- ğŸ’¾ ä¿å­˜ä¿®è®¢ç‰ˆæœ¬ (ç¬¬ {rewrite_attempts - 1} æ¬¡ä¿®è®¢), å¹³å‡åˆ†: {avg_score:.2f} ---")

        # ä¸ºä¸‹ä¸€æ¬¡å¾ªç¯å‡†å¤‡é’ˆå¯¹æ€§ç®€æŠ¥
        revision_brief_for_next_loop = scores

    print("==========================")
    print(f"       é‡å†™æ¬¡æ•° {rewrite_attempts}       ")
    print("==========================")

    # è¿”å›ä¸€ä¸ªå­—å…¸æ¥æ›´æ–°çŠ¶æ€
    return {
        "rewrite_attempts": rewrite_attempts,
        "chapter_versions": current_versions,
        "revision_brief": revision_brief_for_next_loop,  # æ³¨å…¥é’ˆå¯¹æ€§ç®€æŠ¥
        "initial_draft": state["revised_draft"],  # å°†å·²ä¿®è®¢çš„è‰ç¨¿ä½œä¸ºä¸‹ä¸€è½®çš„åˆç¨¿
        "revised_draft": None,
        "suggestions": [],
        "expert_evaluations": [],
        "committee_decision": None
    }


# ==================== æµ‹è¯•å‡½æ•° ====================

def output_parsers():
    """æµ‹è¯•æ‰€æœ‰è¾“å‡ºè§£æå™¨åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•è¾“å‡ºè§£æå™¨åŠŸèƒ½...")

    # æµ‹è¯•æ•…äº‹å»ºè®®
    try:
        suggestions = get_ai_suggestions("ä¸€ä¸ªå…³äºå¤ªç©ºæ¢é™©çš„æ•…äº‹")
        print("âœ… AIå»ºè®®æµ‹è¯•é€šè¿‡")
        print(f"æ ‡é¢˜: {suggestions.get('title')}")
    except Exception as e:
        print(f"âŒ AIå»ºè®®æµ‹è¯•å¤±è´¥: {e}")

    # æµ‹è¯•æ‘˜è¦ç”Ÿæˆ
    try:
        summary = generate_chapter_summary("æµ‹è¯•ç« èŠ‚", "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ç« èŠ‚çš„å†…å®¹")
        print("âœ… æ‘˜è¦ç”Ÿæˆæµ‹è¯•é€šè¿‡")
        print(f"æ‘˜è¦: {summary}")
    except Exception as e:
        print(f"âŒ æ‘˜è¦ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")

    print("ğŸ‰ è¾“å‡ºè§£æå™¨æµ‹è¯•å®Œæˆ")


# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    output_parsers()