import json
from typing import Dict, Any, List
from pydantic import BaseModel, Field

from state import StoryState, ExpertEvaluation
from utils import get_llm, get_evaluation_llm
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import PromptTemplate
from helper import filter_think_tags, parse_json_with_filtering


# ==================== å®šä¹‰ Pydantic æ¨¡å‹ ====================

class DimensionScore(BaseModel):
    score: int = Field(description="ç»´åº¦è¯„åˆ†ï¼ŒèŒƒå›´1-10")
    comment: str = Field(description="ç»´åº¦è¯„è¯­")


class NarrativeExpertEvaluation(BaseModel):
    agent_id: str = Field(default="Narrative_Expert", description="ä»£ç†ID")
    specialization: str = Field(default="å™äº‹ç»“æ„ä¸“å®¶", description="ä¸“ä¸šé¢†åŸŸ")
    dimension_scores: Dict[str, int] = Field(description="ç»´åº¦è¯„åˆ†")
    evaluation_comments: Dict[str, str] = Field(description="ç»´åº¦è¯„è¯­")


class ReaderExperienceEvaluation(BaseModel):
    agent_id: str = Field(default="Reader_Experience_Expert", description="ä»£ç†ID")
    specialization: str = Field(default="è¯»è€…ä½“éªŒä¸“å®¶", description="ä¸“ä¸šé¢†åŸŸ")
    dimension_scores: Dict[str, int] = Field(description="ç»´åº¦è¯„åˆ†")
    evaluation_comments: Dict[str, str] = Field(description="ç»´åº¦è¯„è¯­")


class LiteraryArtEvaluation(BaseModel):
    agent_id: str = Field(default="Literary_Art_Expert", description="ä»£ç†ID")
    specialization: str = Field(default="æ–‡å­¦è‰ºæœ¯ä¸“å®¶", description="ä¸“ä¸šé¢†åŸŸ")
    dimension_scores: Dict[str, int] = Field(description="ç»´åº¦è¯„åˆ†")
    evaluation_comments: Dict[str, str] = Field(description="ç»´åº¦è¯„è¯­")


# ä¸“å®¶é…ç½®



def expert_evaluation_agent(state: StoryState) -> Dict[str, Any]:
    print("--- ğŸŒŸ ä¸“å®¶è¯„åˆ†ç³»ç»Ÿï¼šå¼€å§‹å¯¹æ”¹å†™å†…å®¹è¿›è¡Œå¤šç»´åº¦è¯„ä¼°... ---")
    experts_config = [
        {
            "id": "Narrative_Expert",
            "specialization": "å™äº‹ç»“æ„ä¸“å®¶",
            "focus": "æ“…é•¿æ•´ä½“å™äº‹æ¶æ„å’Œæƒ…èŠ‚æ¨è¿›é€»è¾‘è¯„ä¼°",
            "evaluation_focus": "ä»å™äº‹ç³»ç»Ÿæ•´ä½“æ€§å‡ºå‘ï¼Œè¯„ä¼°æ•…äº‹ç»“æ„çš„å®Œæ•´æ€§å’Œé€»è¾‘è‡ªæ´½æ€§",
            "model_class": NarrativeExpertEvaluation,
            "dimensions": [
                {
                    "id": "worldview_integration",
                    "name": "ä¸–ç•Œè§‚-æƒ…èŠ‚èåˆåº¦",
                    "description": "è¯„ä¼°ä¸–ç•Œè§‚è®¾å®šä¸æƒ…èŠ‚å‘å±•çš„æ·±åº¦æ•´åˆï¼Œç§‘æŠ€/é­”æ³•ä½“ç³»æ˜¯å¦æœ‰æœºå½±å“æ•…äº‹èµ°å‘",
                    "score_examples": [
                        "1-3åˆ†ï¼šä¸–ç•Œè§‚ä¸æƒ…èŠ‚å®Œå…¨è„±èŠ‚ï¼Œè®¾å®šä»…ä¸ºè£…é¥°æ€§èƒŒæ™¯",
                        "4-6åˆ†ï¼šä¸–ç•Œè§‚èƒ½æ”¯æ’‘åŸºæœ¬æƒ…èŠ‚ä½†ç¼ºä¹æ·±åº¦äº’åŠ¨",
                        "7-10åˆ†ï¼šä¸–ç•Œè§‚è§„åˆ™æ·±åº¦é©±åŠ¨æƒ…èŠ‚å‘å±•ï¼Œå½¢æˆæœ‰æœºæ•´ä½“"
                    ],
                    "comment_examples": [
                        "ä¼˜ç‚¹ï¼šå›¾ä¹¦é¦†çš„è…æœ½ç»†èŠ‚ä¸åºŸå¼ƒåŸå› å½¢æˆå‘¼åº”ï¼›ä¸è¶³ï¼šæŒ‚å ç›’çš„èƒ½é‡æ¥æºæœªå……åˆ†èå…¥ä¸–ç•Œè§‚ä½“ç³»"
                    ]
                },
                {
                    "id": "narrative_coherence",
                    "name": "å™äº‹é€»è¾‘è¿è´¯æ€§",
                    "description": "è¯„ä¼°æƒ…èŠ‚æ¨è¿›çš„é€»è¾‘åˆç†æ€§ï¼Œä¼ç¬”ä¸è§£è°œçš„å‘¼åº”å…³ç³»",
                    "score_examples": [
                        "1-3åˆ†ï¼šæƒ…èŠ‚å‘å±•ç¼ºä¹é€»è¾‘åŸºç¡€ï¼Œè¡Œä¸ºåŠ¨æœºä¸æ˜ç¡®",
                        "4-6åˆ†ï¼šåŸºæœ¬é€»è¾‘åˆç†ä½†å­˜åœ¨ç‰µå¼ºä¹‹å¤„",
                        "7-10åˆ†ï¼šæƒ…èŠ‚å‘å±•è‡ªç„¶æµç•…ï¼Œå‰åå‘¼åº”å½¢æˆå®Œæ•´é€»è¾‘é“¾"
                    ],
                    "comment_examples": [
                        "ä¼˜ç‚¹ï¼šç¥–çˆ¶æ—¥è®°ä½œä¸ºçº¿ç´¢è´¯ç©¿å§‹ç»ˆï¼›ä¸è¶³ï¼šå¦¹å¦¹å›å¿†ä¸å½“å‰æ¢ç´¢çš„å…³è”é€»è¾‘éœ€åŠ å¼º"
                    ]
                }
            ]
        },
        {
            "id": "Reader_Experience_Expert",
            "specialization": "è¯»è€…ä½“éªŒä¸“å®¶",
            "focus": "ä¸“æ³¨äºè¯»è€…ä»£å…¥æ„Ÿã€æƒ…æ„Ÿå…±é¸£å’Œé˜…è¯»èˆ’é€‚åº¦è¯„ä¼°",
            "evaluation_focus": "ä»æ™®é€šè¯»è€…è§†è§’è¯„ä¼°å†…å®¹çš„å¯è¯»æ€§ã€æƒ…æ„Ÿå†²å‡»åŠ›å’Œæ³¨æ„åŠ›ä¿æŒæ•ˆæœ",
            "model_class": ReaderExperienceEvaluation,
            "dimensions": [
                {
                    "id": "emotional_accessibility",
                    "name": "æƒ…æ„Ÿå…±é¸£æ˜“è¾¾æ€§",
                    "description": "è¯„ä¼°æƒ…æ„Ÿæå†™æ˜¯å¦èƒ½è®©ä¸åŒèƒŒæ™¯è¯»è€…å¿«é€Ÿäº§ç”Ÿå…±é¸£å’Œä»£å…¥æ„Ÿ",
                    "score_examples": [
                        "1-3åˆ†ï¼šæƒ…æ„Ÿè¡¨è¾¾æŠ½è±¡æ™¦æ¶©ï¼Œéš¾ä»¥å¼•å‘è¯»è€…å…±é¸£",
                        "4-6åˆ†ï¼šæƒ…æ„Ÿåˆç†ä½†ç¼ºä¹å…·è±¡ç»†èŠ‚æ”¯æ’‘",
                        "7-10åˆ†ï¼šé€šè¿‡å…·ä½“è¡Œä¸ºå’Œç»†èŠ‚è‡ªç„¶ä¼ é€’æƒ…æ„Ÿï¼Œè¯»è€…èƒ½è½»æ¾ä»£å…¥"
                    ],
                    "comment_examples": [
                        "ä¼˜ç‚¹ï¼šå¦¹å¦¹ç¬‘å®¹çš„å›å¿†ç”¨'é©±æ•£é˜´éœ¾'å»ºç«‹æƒ…æ„Ÿè¿æ¥ï¼›ä¸è¶³ï¼šææƒ§æƒ…ç»ªæå†™å¯å¢åŠ æ›´å¤šç”Ÿç†ååº”ç»†èŠ‚"
                    ]
                },
                {
                    "id": "sensory_immersion",
                    "name": "å¤šæ„Ÿå®˜æ²‰æµ¸ä½“éªŒ",
                    "description": "è¯„ä¼°æ„Ÿå®˜ç»†èŠ‚çš„ä¸°å¯Œåº¦å’Œå±‚æ¬¡æ„Ÿï¼Œèƒ½å¦è®©è¯»è€…å¿«é€Ÿæ„å»ºç”ŸåŠ¨åœºæ™¯æƒ³è±¡",
                    "score_examples": [
                        "1-3åˆ†ï¼šæ„Ÿå®˜æå†™å•ä¸€æˆ–ç¼ºå¤±ï¼Œåœºæ™¯æƒ³è±¡å›°éš¾",
                        "4-6åˆ†ï¼šæœ‰åŸºæœ¬æ„Ÿå®˜æå†™ä½†ç¼ºä¹å±‚æ¬¡å’Œç»†èŠ‚",
                        "7-10åˆ†ï¼šå¤šæ„Ÿå®˜è”åŠ¨å½¢æˆç«‹ä½“ä½“éªŒï¼Œåœºæ™¯æ ©æ ©å¦‚ç”Ÿ"
                    ],
                    "comment_examples": [
                        "ä¼˜ç‚¹ï¼šæŒ‚å ç›’çš„æ¸©åº¦å˜åŒ–æä¾›æ˜ç¡®è§¦è§‰é”šç‚¹ï¼›ä¸è¶³ï¼šç¯å¢ƒå£°éŸ³å’Œæ°”å‘³ç»†èŠ‚å¯è¿›ä¸€æ­¥ä¸°å¯Œ"
                    ]
                }
            ]
        },
        {
            "id": "Literary_Art_Expert",
            "specialization": "æ–‡å­¦è‰ºæœ¯ä¸“å®¶",
            "focus": "æ“…é•¿ä»æ–‡å­¦æŠ€å·§å’Œè‰ºæœ¯è¡¨è¾¾è§’åº¦è¯„ä¼°å†…å®¹è´¨é‡",
            "evaluation_focus": "ä»æ–‡å­¦åˆ›ä½œè§’åº¦è¯„ä¼°è¡¨è¾¾çš„è‰ºæœ¯æ€§ã€åˆ›æ–°æ€§å’Œç¾å­¦ä»·å€¼",
            "model_class": LiteraryArtEvaluation,
            "dimensions": [
                {
                    "id": "foreshadowing_artistry",
                    "name": "ä¼ç¬”è‰ºæœ¯è¡¨ç°åŠ›",
                    "description": "è¯„ä¼°ä¼ç¬”è®¾ç½®çš„å·§å¦™ç¨‹åº¦ï¼Œæ˜¯å¦é€šè¿‡éšå–»/è±¡å¾æ‰‹æ³•å‘ˆç°å¤šä¹‰è§£è¯»ç©ºé—´",
                    "score_examples": [
                        "1-3åˆ†ï¼šä¼ç¬”ç›´ç™½ç”Ÿç¡¬ï¼Œç¼ºä¹è‰ºæœ¯å¤„ç†",
                        "4-6åˆ†ï¼šæœ‰åŸºæœ¬ä¼ç¬”ä½†è±¡å¾å•ä¸€ï¼Œè§£è¯»ç©ºé—´æœ‰é™",
                        "7-10åˆ†ï¼šä¼ç¬”å·§å¦™èå…¥å™äº‹ï¼Œå…·å¤‡å¤šå±‚æ¬¡è±¡å¾æ„ä¹‰"
                    ],
                    "comment_examples": [
                        "ä¼˜ç‚¹ï¼šæœˆå…‰'å¦‚åŒæ—¶å…‰æµé€'æ—¢å†™æ™¯åˆæš—ç¤ºæ—¶é—´çº¿ç´¢ï¼›ä¸è¶³ï¼šé”é“¾å£°å“çš„è±¡å¾æ„ä¹‰å¯è¿›ä¸€æ­¥æŒ–æ˜"
                    ]
                },
                {
                    "id": "language_rhythm",
                    "name": "è¯­è¨€èŠ‚å¥è‰ºæœ¯æ€§",
                    "description": "è¯„ä¼°å¥å¼ç»“æ„ã€æ ‡ç‚¹è¿ç”¨å¯¹å™äº‹èŠ‚å¥çš„è°ƒæ§æ•ˆæœ",
                    "score_examples": [
                        "1-3åˆ†ï¼šå¥å¼å•è°ƒå¹³æ¿ï¼Œç¼ºä¹èŠ‚å¥å˜åŒ–",
                        "4-6åˆ†ï¼šæœ‰èŠ‚å¥å˜åŒ–ä½†ä¸æƒ…èŠ‚æƒ…ç»ªåŒ¹é…åº¦ä¸é«˜",
                        "7-10åˆ†ï¼šè¯­è¨€èŠ‚å¥ç²¾å‡†åŒ¹é…æƒ…èŠ‚èµ·ä¼ï¼Œå¢å¼ºå™äº‹å¼ åŠ›"
                    ],
                    "comment_examples": [
                        "ä¼˜ç‚¹ï¼šç¯å¢ƒæå†™ç”¨é•¿å¥è¥é€ æ²‰æµ¸æ„Ÿï¼Œçªå‘å£°å“ç”¨çŸ­å¥åˆ¶é€ å†²å‡»ï¼›ä¸è¶³ï¼šå›å¿†ä¸ç°å®é—´çš„èŠ‚å¥è¿‡æ¸¡å¯ä¼˜åŒ–"
                    ]
                },
                {
                    "id": "structural_innovation",
                    "name": "å™äº‹ç»“æ„åˆ›æ–°æ€§",
                    "description": "è¯„ä¼°æ—¶ç©ºè½¬æ¢ã€è§†è§’åˆ‡æ¢ç­‰ç»“æ„æ‰‹æ³•çš„è‰ºæœ¯è¿ç”¨æ•ˆæœ",
                    "score_examples": [
                        "1-3åˆ†ï¼šç»“æ„ä¼ ç»Ÿå•ä¸€ï¼Œç¼ºä¹åˆ›æ–°è¡¨è¾¾",
                        "4-6åˆ†ï¼šæœ‰ç»“æ„å˜åŒ–ä½†æ‰‹æ³•å¸¸è§„",
                        "7-10åˆ†ï¼šç»“æ„æ‰‹æ³•åˆ›æ–°ä¸”æœåŠ¡äºä¸»é¢˜è¡¨è¾¾ï¼Œå¢å¼ºè‰ºæœ¯æ„ŸæŸ“åŠ›"
                    ],
                    "comment_examples": [
                        "ä¼˜ç‚¹ï¼šç”¨æŒ‚å ç›’ä½œä¸ºæ—¶ç©ºè½¬æ¢é”šç‚¹ï¼›ä¸è¶³ï¼šç« èŠ‚ç»“å°¾æ‚¬å¿µè®¾ç½®çš„è‰ºæœ¯æ€§å¯åŠ å¼º"
                    ]
                }
            ]
        }
    ]
    revised_draft = state.get('revised_draft')
    if not revised_draft:
        print("--- âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ°æ”¹å†™åçš„è‰ç¨¿å†…å®¹ ---")
        return {"expert_evaluations": []}

    state["expert_evaluations"] = None
    all_evaluations: List[ExpertEvaluation] = []

    for expert in experts_config:
        print(f"--- ğŸ‘¤ {expert['specialization']} æ­£åœ¨è¯„åˆ†... ---")

        # åˆ›å»ºè¾“å‡ºè§£æå™¨
        parser = PydanticOutputParser(pydantic_object=expert["model_class"])

        # ç”Ÿæˆä¸“å®¶ä¸“å±ç»´åº¦æè¿°
        dimension_descriptions = "\n".join([
            f"- {dim['id']}: {dim['name']}\n"
            f"æè¿°ï¼š{dim['description']}\n"
            f"è¯„åˆ†å‚è€ƒï¼š{'; '.join(dim['score_examples'])}\n"
            f"è¯„è¯­ç¤ºä¾‹ï¼š{dim['comment_examples'][0]}"
            for dim in expert["dimensions"]
        ])

        # æ„å»ºæç¤ºè¯æ¨¡æ¿
        prompt_template = """
ä½ æ˜¯ä¸€åèµ„æ·±çš„{specialization}ï¼Œä¸“æ³¨äº{focus}ï¼Œæ ¸å¿ƒè¯„ä¼°å‡†åˆ™ï¼š{evaluation_focus}ã€‚
è¯·åŸºäºä»¥ä¸‹å†…å®¹ï¼Œä»…ä»ä½ ä¸“ç²¾çš„ç»´åº¦è¿›è¡Œè¯„åˆ†ï¼ˆå…¶ä»–ç»´åº¦æ— éœ€å…³æ³¨ï¼‰ï¼š

**æ”¹å†™åç« èŠ‚å†…å®¹**:
{revised_draft}

**ä½ çš„ä¸“å±è¯„åˆ†ç»´åº¦åŠè¯´æ˜**:
{dimension_descriptions}

**è¯„åˆ†è¦æ±‚**:
1. æ¯ä¸ªç»´åº¦è¯„åˆ†èŒƒå›´ä¸º1-10åˆ†ï¼Œä¸¥æ ¼å‚è€ƒä½ çš„ä¸“å±è¯„åˆ†ç¤ºä¾‹
2. è¯„è¯­éœ€ç»“åˆä½ çš„ä¸“ä¸šè§†è§’ï¼ˆå¦‚è¯»è€…ä½“éªŒ/æ–‡å­¦æŠ€å·§ï¼‰
3. å¿…é¡»ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šJSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–å†…å®¹

**è¾“å‡ºè¦æ±‚**:
è¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼æä¾›è¯„ä¼°æŠ¥å‘Šã€‚

{format_instructions}
"""

        llm = get_evaluation_llm()

        try:
            prompt = PromptTemplate(
                template=prompt_template,
                input_variables=["specialization", "focus", "evaluation_focus", "revised_draft",
                                 "dimension_descriptions"],
                partial_variables={"format_instructions": parser.get_format_instructions()}
            )

            chain = prompt | llm
            raw_response = chain.invoke({
                "specialization": expert["specialization"],
                "focus": expert["focus"],
                "evaluation_focus": expert["evaluation_focus"],
                "revised_draft": revised_draft,
                "dimension_descriptions": dimension_descriptions
            })

            # è¿‡æ»¤æ€è€ƒæ ‡ç­¾å¹¶è§£æ
            filtered_content = filter_think_tags(raw_response.content)
            parsed_evaluation = parse_json_with_filtering(filtered_content, parser)

            all_evaluations.append(parsed_evaluation.model_dump())
            print(f"--- âœ… {expert['specialization']} è¯„åˆ†å®Œæˆ ---")

        except Exception as e:
            print(f"--- âŒ {expert['specialization']} è¯„åˆ†å¤±è´¥: {e} ---")
            # æ·»åŠ é”™è¯¯è¯„ä¼°ä½œä¸ºå ä½ç¬¦
            error_evaluation = {
                "agent_id": expert["id"],
                "specialization": expert["specialization"],
                "dimension_scores": {dim["id"]: 0 for dim in expert["dimensions"]},
                "evaluation_comments": {dim["id"]: f"è¯„åˆ†å¤±è´¥: {str(e)}" for dim in expert["dimensions"]}
            }
            all_evaluations.append(error_evaluation)

    print("--- ğŸ æ‰€æœ‰ä¸“å®¶è¯„åˆ†å®Œæˆ ---")
    return {"expert_evaluations": all_evaluations}


# ==================== æµ‹è¯•å‡½æ•° ====================

def expert_evaluation_agent0():
    """æµ‹è¯•ä¸“å®¶è¯„ä¼° Agent"""
    print("ğŸ§ª æµ‹è¯•ä¸“å®¶è¯„ä¼° Agent...")

    # åˆ›å»ºæ¨¡æ‹ŸçŠ¶æ€
    test_state: StoryState = {
        "revised_draft": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ç« èŠ‚å†…å®¹ã€‚ä¸»è§’åœ¨åºŸå¼ƒçš„å›¾ä¹¦é¦†ä¸­å‘ç°äº†ä¸€ä¸ªç¥ç§˜çš„æŒ‚å ç›’ï¼ŒæŒ‚å ç›’æ•£å‘ç€å¾®å¼±çš„å…‰èŠ’ã€‚å½“ä»–è§¦æ‘¸æŒ‚å ç›’æ—¶ï¼Œè„‘æµ·ä¸­æµ®ç°å‡ºå¦¹å¦¹çš„ç¬‘å®¹ï¼Œè¿™è®©ä»–ä¸‹å®šå†³å¿ƒè¦ç»§ç»­æ¢ç´¢ä¸‹å»ã€‚",
        "expert_evaluations": None,
        "agent_flags": {}
    }

    result = expert_evaluation_agent(test_state)
    print("ä¸“å®¶è¯„ä¼° Agent æµ‹è¯•ç»“æœ:")
    # print(f"è¯„ä¼°æ•°é‡: {len(result.get('expert_evaluations', []))}")
    #
    # for evaluation in result.get('expert_evaluations', []):
    #     print(f"ä¸“å®¶: {evaluation.get('specialization', 'æœªçŸ¥')}")
    #     print(f"ç»´åº¦è¯„åˆ†: {evaluation.get('dimension_scores', {})}")
    #     print("---")
    print(result)

    return True


def expert_evaluation_empty_draft0():
    """æµ‹è¯•ä¸“å®¶è¯„ä¼° Agent æ— è‰ç¨¿æƒ…å†µ"""
    print("ğŸ§ª æµ‹è¯•ä¸“å®¶è¯„ä¼° Agent æ— è‰ç¨¿æƒ…å†µ...")

    # åˆ›å»ºæ¨¡æ‹ŸçŠ¶æ€ - æ²¡æœ‰è‰ç¨¿
    test_state: StoryState = {
        "revised_draft": None,
        "expert_evaluations": None,
        "agent_flags": {}
    }

    result = expert_evaluation_agent(test_state)
    print("ä¸“å®¶è¯„ä¼° Agent æ— è‰ç¨¿æµ‹è¯•ç»“æœ:")
    print(f"è¯„ä¼°åˆ—è¡¨ä¸ºç©º: {result.get('expert_evaluations') == []}")
    return True


def run_all_evaluation_tests():
    """è¿è¡Œæ‰€æœ‰ Evaluation Agents æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æµ‹è¯• Evaluation Agents...\n")

    expert_evaluation_agent0()
    expert_evaluation_empty_draft0()

    return


# åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ ä»¥ä¸‹ä»£ç æ¥è¿è¡Œæµ‹è¯•
if __name__ == "__main__":
    # å¦‚æœç›´æ¥è¿è¡Œè¿™ä¸ªæ–‡ä»¶ï¼Œæ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    run_all_evaluation_tests()